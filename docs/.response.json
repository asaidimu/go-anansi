{
  "classification": {
    "primaryType": "Development Framework",
    "confidence": 0.98,
    "characteristics": [
      "Schema-Driven Data Modeling",
      "Pluggable Persistence Layer",
      "Declarative Query DSL",
      "Comprehensive CRUD Operations",
      "In-memory Go-based Processing",
      "Transaction Management",
      "Event-Driven Architecture",
      "Runtime Data Validation"
    ],
    "adaptations": [
      "Focused on Go module structure and idioms.",
      "Emphasis on interface contracts for extensibility.",
      "Detailed Go type definitions for data structures.",
      "Examples provided in Go language."
    ]
  },
  "introduction": "Anansi is a comprehensive toolkit for defining, versioning, migrating, and persisting structured data, enabling schema-driven development with powerful runtime validation and adaptable storage layers. This repository provides the **Go implementation** of the Anansi persistence and query framework.\n\nAnansi is designed to bring a robust, schema-first approach to data persistence in Go applications. By externalizing data models into declarative JSON schema definitions, it allows for dynamic table creation, powerful querying, and a clear pathway for future data migrations and versioning. This framework aims to provide a high degree of flexibility and extensibility by abstracting the underlying storage mechanism.\n\nThe current implementation focuses on providing a production-ready SQLite adapter, demonstrating the core capabilities of the Anansi framework. While SQLite is the primary target for initial development, the architecture is built to support other database systems through a pluggable `DatabaseInteractor` and `QueryGeneratorFactory` interface. This project is still under active development, with several advanced features defined in interfaces awaiting full implementation.\n\n**Key Features:**\n\n*   **Schema-Driven Data Modeling**: Define your data structures using declarative JSON schemas (`core.SchemaDefinition`) that include field types, constraints (required, unique, default), and indexing.\n*   **Pluggable Persistence Layer**: Anansi is built around interfaces (`persistence.DatabaseInteractor`, `query.QueryGeneratorFactory`, `query.QueryGenerator`) allowing easy integration with various database systems. The initial release provides a comprehensive SQLite adapter.\n*   **Declarative Query DSL**: Construct complex queries using a fluent `query.QueryBuilder` API, which is then translated into efficient SQL statements by the underlying query generator.\n*   **Comprehensive CRUD Operations**: Perform `Create`, `Read`, `Update`, and `Delete` operations on your collections through a unified `core.PersistenceCollectionInterface`.\n*   **Nested JSON Field Querying**: Seamlessly query and filter on data stored within JSON object fields in your database, treating them as first-class fields using `json_extract` for SQLite.\n*   **In-memory Go-based Processing**: Extend query capabilities with custom Go functions for:\n    *   **Computed Fields**: Define new fields dynamically by applying Go logic to retrieved data.\n    *   **Custom Filters**: Implement complex, non-SQL-standard filtering logic in Go after initial database retrieval.\n*   **Table & Index Management**: Programmatically create and manage database tables and indexes directly from your schema definitions, supporting `IF NOT EXISTS`, `DROP TABLE IF EXISTS`, and various index types.\n*   **Atomic Insert Operations**: Utilizes `RETURNING *` for `INSERT` statements (where supported, e.g., SQLite 3.35+) to atomically fetch inserted records, including auto-generated IDs and default values.\n*   **Transaction Management**: Supports explicit database transactions (`StartTransaction`, `Commit`, `Rollback`) and a higher-level `Transact` method for atomic operations across multiple collections.\n*   **Event-Driven Architecture**: Register subscriptions to various persistence lifecycle events (e.g., document creation, deletion) for reactive programming and auditing.\n*   **Robust Error Handling & Logging**: Integrates with `go.uber.org/zap` for structured logging, aiding debugging and operational insights.\n*   **Data Validation**: Perform runtime validation of data against defined schemas using `collection.Validate`."
  },
  "sections": [
    {
      "title": "Getting Started",
      "path": "getting-started.md",
      "content": "### Overview\nAnansi simplifies data persistence in Go by providing a schema-driven approach. You define your data models declaratively using JSON schemas, and Anansi handles the underlying database interactions, including table creation, querying, and validation. The framework is designed for extensibility, allowing you to easily plug in different database backends. The current implementation offers a production-ready SQLite adapter.\n\n### Quick Setup Guide\nTo get started with Anansi, you need Go (1.24.4+) and the SQLite C library installed.\n\n1.  **Clone the repository:**\n    ```bash\n    git clone https://github.com/asaidimu/go-anansi.git\n    cd go-anansi\n    ```\n2.  **Download dependencies:**\n    ```bash\n    go mod tidy\n    ```\n3.  **Run the example application:**\n    ```bash\n    go run main.go\n    ```\n    This will create a `user.db` file, demonstrate schema creation, data manipulation, and querying.\n\n### First Tasks with Decision Patterns\n#### 1. Initializing the Persistence Layer\n**Goal**: Connect to a database and prepare the Anansi persistence service.\n**Decision**: Choose the appropriate `persistence.DatabaseInteractor` for your database (currently, `sqlite.NewSQLiteInteractor` is available).\n\n```go\nimport (\n\t\"database/sql\"\n\t\"log\"\n\t\"os\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n\t\"github.com/asaidimu/go-anansi/sqlite\"\n\t_ \"github.com/mattn/go-sqlite3\" // SQLite driver\n\t\"go.uber.org/zap\"\n)\n\nfunc initializePersistence() (*persistence.Persistence, error) {\n\t// For demonstration, remove old db file\n\t_ = os.Remove(\"my_app.db\") \n\n\tdb, err := sql.Open(\"sqlite3\", \"my_app.db\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to open database connection: %w\", err)\n\t}\n\t// Defer db.Close() in your main function\n\n\tlogger := zap.NewNop() // Or zap.NewDevelopment()\n\n\t// Create the SQLite-specific interactor\n\tinteractor := sqlite.NewSQLiteInteractor(db, logger, nil, nil)\n\n\t// Initialize the core persistence layer with an empty FunctionMap for custom functions\n\tpersistenceSvc, err := persistence.NewPersistence(interactor, core.FunctionMap{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to initialize persistence: %w\", err)\n\t}\n\treturn persistenceSvc, nil\n}\n```\n\n#### 2. Defining and Creating a Collection (Table)\n**Goal**: Define your data structure and create the corresponding database table.\n**Decision**: Use `core.SchemaDefinition` and `persistence.Persistence.Create()`.\n\n```go\nimport (\n\t\"encoding/json\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n)\n\nfunc createUsersCollection(persistenceSvc *persistence.Persistence) (core.PersistenceCollectionInterface, error) {\n\tuserSchemaJSON := `{ \"name\": \"users\", \"version\": \"1.0.0\", \"description\": \"User profiles\", \"fields\": {\"id\": {\"type\": \"integer\", \"unique\": true}, \"name\": {\"type\": \"string\", \"required\": true}}, \"indexes\": [{\"name\": \"pk_user_id\", \"fields\": [\"id\"], \"type\": \"primary\"}]}`\n\n\tvar userSchema core.SchemaDefinition\n\tif err := json.Unmarshal([]byte(userSchemaJSON), &userSchema); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to unmarshal user schema JSON: %w\", err)\n\t}\n\n\tcollection, err := persistenceSvc.Create(userSchema)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create collection 'users': %w\", err)\n\t}\n\treturn collection, nil\n}\n```",
      "agentGuidance": {
        "decisionPoints": [
          "IF [user needs database interaction] THEN [initialize persistence.DatabaseInteractor] ELSE [skip database setup]",
          "IF [user needs to define a new data structure] THEN [create core.SchemaDefinition and call persistence.Persistence.Create()] ELSE [use existing collection]"
        ],
        "verificationSteps": [
          "Check: `err == nil` after `sql.Open()` and `persistence.NewPersistence()` to confirm successful initialization.",
          "Check: `err == nil` after `json.Unmarshal()` and `persistenceSvc.Create()` to confirm schema definition and collection creation.",
          "Check: Database file (`user.db` in example) exists and contains expected tables using `sqlite3` command-line tool."
        ],
        "quickPatterns": [
          "Pattern: Database Initialization\n```go\ndb, err := sql.Open(\"sqlite3\", \"[DB_FILE_NAME].db\")\ninteractor := sqlite.NewSQLiteInteractor(db, zap.NewNop(), nil, nil)\npersistenceSvc, err := persistence.NewPersistence(interactor, core.FunctionMap{})\n```",
          "Pattern: Collection Creation\n```go\nvar mySchema core.SchemaDefinition\n// ... unmarshal schema JSON ...\ncollection, err := persistenceSvc.Create(mySchema)\n```"
        ],
        "diagnosticPaths": [
          "Error `Failed to open database connection` -> Symptom: Application cannot connect to SQLite -> Check: Ensure `github.com/mattn/go-sqlite3` driver is imported and SQLite C library is installed on the system -> Fix: Run `go mod tidy` and install SQLite C library (`sudo apt-get install sqlite3 libsqlite3-dev` for Debian/Ubuntu)."
        ]
      }
    },
    {
      "title": "Core Operations",
      "path": "core-operations.md",
      "content": "Anansi provides a unified API for standard CRUD (Create, Read, Update, Delete) operations on your collections.\n\n### Create (Insert Documents)\nThe `Create` method handles both single and batch insertions of documents into a collection. Documents are typically `map[string]any`.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc createDocuments(collection core.PersistenceCollectionInterface) {\n\t// Single record insert\n\tuserData := map[string]any{\n\t\t\"name\":      \"Alice Smith\",\n\t\t\"email\":     \"alice@example.com\",\n\t\t\"age\":       30,\n\t\t\"is_active\": true,\n\t}\n\tinsertedResult, err := collection.Create(userData)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to insert single user: %v\", err)\n\t}\n\tfmt.Printf(\"Inserted user with ID: %v\\n\", insertedResult.(*query.QueryResult).Data.(query.Document)[\"id\"])\n\n\t// Batch inserts\n\tbatchData := []map[string]any{\n\t\t{\"name\": \"Bob Johnson\", \"email\": \"bob@example.com\", \"age\": 25, \"is_active\": true},\n\t\t{\"name\": \"Charlie Brown\", \"email\": \"charlie@example.com\", \"age\": 35, \"is_active\": false},\n\t}\n\tinsertedBatchResult, err := collection.Create(batchData)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to batch insert users: %v\", err)\n\t}\n\tfmt.Printf(\"Batch inserted %d users.\\n\", insertedBatchResult.(*query.QueryResult).Count)\n}\n```\n\n### Read (Query Documents)\n`Read` operations utilize the `query.QueryDSL` to define complex queries, including filtering, sorting, and pagination.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc readDocuments(collection core.PersistenceCollectionInterface) {\n\t// Query all users where age is 28\n\tq := query.NewQueryBuilder().Where(\"age\").Eq(28).Build()\n\n\tout, err := collection.Read(q)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to read data: %v\", err)\n\t}\n\n\tresult, ok := out.(*query.QueryResult)\n\tif !ok {\n\t\tlog.Fatalf(\"Unexpected result type from Read operation\")\n\t}\n\trows := result.Data.([]query.Document) // Data is a slice of map[string]any\n\n\tfmt.Println(\"\\n--- Users aged 28 ---\")\n\tfor _, row := range rows {\n\t\tfmt.Printf(\"ID: %v, Name: %v, Email: %v, Age: %v, Active: %v\\n\",\n\t\t\trow[\"id\"], row[\"name\"], row[\"email\"], row[\"age\"], row[\"is_active\"])\n\t}\n}\n```\n\n### Update (Update Documents)\nThe `Update` method modifies documents matching a specified filter. It returns the number of rows affected.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc updateDocuments(collection core.PersistenceCollectionInterface) {\n\t// Update all users named \"Alice Smith\" to \"Alex Smith\"\n\tupdates := map[string]any{\"name\": \"Alex Smith\"}\n\tfilter := query.NewQueryBuilder().Where(\"name\").Eq(\"Alice Smith\").Build().Filters\n\n\tupdateParams := &core.CollectionUpdate{\n\t\tData:   updates,\n\t\tFilter: filter,\n\t}\n\n\trowsAffected, err := collection.Update(updateParams)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to update user: %v\", err)\n\t}\n\tfmt.Printf(\"Updated %d rows.\\n\", rowsAffected)\n}\n```\n\n### Delete (Delete Documents)\nThe `Delete` method removes documents from a collection based on a filter. For safety, it requires a filter unless explicitly overridden.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc deleteDocuments(collection core.PersistenceCollectionInterface) {\n\t// Delete inactive users\n\tfilter := query.NewQueryBuilder().Where(\"is_active\").Eq(false).Build().Filters\n\n\t// To delete all records (use with caution in production):\n\t// rowsAffected, err := collection.Delete(nil, true) \n\n\trowsAffected, err := collection.Delete(filter, false)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to delete users: %v\", err)\n\t}\n\tfmt.Printf(\"Deleted %d rows.\\n\", rowsAffected)\n}\n```",
      "agentGuidance": {
        "decisionPoints": [
          "IF [user wants to add new data] THEN [use `collection.Create(data)`].",
          "IF [user wants to retrieve data] THEN [use `collection.Read(query.NewQueryBuilder()...Build())`].",
          "IF [user wants to modify existing data] THEN [use `collection.Update(&core.CollectionUpdate{Data: updates, Filter: filters})`].",
          "IF [user wants to remove data] THEN [use `collection.Delete(filters, unsafe)`]."
        ],
        "verificationSteps": [
          "Check: `err == nil` after `Create`, `Read`, `Update`, `Delete` operations.",
          "Check: For `Create`, verify `QueryResult.Data` contains the inserted document(s) and `QueryResult.Count` is correct.",
          "Check: For `Read`, verify `QueryResult.Data` contains expected documents and `QueryResult.Count` matches.",
          "Check: For `Update` and `Delete`, verify the returned `int` (rowsAffected) matches expectation."
        ],
        "quickPatterns": [
          "Pattern: Insert Single Document\n```go\ncollection.Create(map[string]any{\"field1\": \"value1\"})\n```",
          "Pattern: Read All Documents\n```go\nresults, err := collection.Read(query.NewQueryBuilder().Build())\n```",
          "Pattern: Update Documents by Filter\n```go\ncollection.Update(&core.CollectionUpdate{\n    Data: map[string]any{\"field\": \"new_value\"},\n    Filter: query.NewQueryBuilder().Where(\"id\").Eq(1).Build().Filters,\n})\n```",
          "Pattern: Delete Documents by Filter\n```go\ncollection.Delete(query.NewQueryBuilder().Where(\"status\").Eq(\"inactive\").Build().Filters, false)\n```"
        ],
        "diagnosticPaths": [
          "Error `Provided data does not conform to the collections schema` -> Symptom: Data cannot be inserted -> Check: Review `core.SchemaDefinition` for required fields, types, and constraints. Use `collection.Validate()` for detailed issues. -> Fix: Adjust input data to match schema or modify schema definition.",
          "Error `failed to insert data` -> Symptom: Database insertion failed -> Check: Underlying database logs for SQL errors. Database connection status. -> Fix: Correct SQL syntax if manually generated or database configuration issues.",
          "Error `invalid params type for Update` / `Delete` -> Symptom: Method calls fail due to incorrect argument types -> Check: Ensure `Filter` for Update/Delete is `*query.QueryFilter` and `Data` for Create is `map[string]any` or `[]map[string]any`. -> Fix: Cast or build query DSL correctly."
        ]
      }
    },
    {
      "title": "Task-Based Guide",
      "path": "task-based-guide.md",
      "content": "Anansi offers advanced capabilities beyond basic CRUD, enabling complex querying, custom Go-based logic, and event-driven patterns.\n\n### Advanced Querying with QueryDSL\nThe `query.QueryBuilder` provides a rich fluent API for constructing declarative queries, which are then translated into optimized SQL by the underlying `QueryGenerator`.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc advancedQuerying(collection core.PersistenceCollectionInterface) {\n\t// Example: Get active users, ordered by age descending, with a limit of 10 and offset of 5,\n\t// and only include the 'name' and 'email' fields in the output.\n\tqueryDSL := query.NewQueryBuilder().\n\t\tWhere(\"is_active\").Eq(true). // Filter: is_active = true\n\t\tOrderByDesc(\"age\").         // Sort by age descending\n\t\tLimit(10).Offset(5).        // Paginate: 10 results, starting from offset 5\n\t\tSelect().\n\t\t\tInclude(\"name\", \"email\"). // Project: only name and email\n\t\tEnd().\n\t\tBuild()\n\n\tresult, err := collection.Read(queryDSL)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to read data with advanced query: %v\", err)\n\t}\n\tfmt.Println(\"\\n--- Advanced Query Results ---\")\n\tfor _, r := range result.(*query.QueryResult).Data.([]query.Document) {\n\t\tfmt.Printf(\"Name: %v, Email: %v\\n\", r[\"name\"], r[\"email\"])\n\t}\n}\n```\n\n**Supported QueryDSL Features (conceptual, some are stubs):**\n\n*   **Filters**: Comparison Operators (`Eq`, `Neq`, `Lt`, `Lte`, `Gt`, `Gte`, `In`, `Nin`, `Contains`, `NotContains`, `StartsWith`, `EndsWith`, `Exists`, `NotExists`), Logical Operators (`WhereGroup` with `And`, `Or`, etc.).\n*   **Sorting**: `OrderByAsc`, `OrderByDesc` for single or multiple fields.\n*   **Pagination**: `Limit`, `Offset` for traditional pagination; `Cursor` for cursor-based.\n*   **Projection**: `Select().Include(...)` or `Select().Exclude(...)` to control returned fields, `AddComputed` for Go-based computed fields, `AddCase` for Go-based `CASE` expressions.\n*   **Joins**: `InnerJoin`, `LeftJoin`, `RightJoin`, `FullJoin`.\n*   **Aggregations**: `Count`, `Sum`, `Avg`, `Min`, `Max`.\n*   **Query Hints**: `UseIndex`, `ForceIndex`, `NoIndex`, `MaxExecutionTime`.\n\n### In-memory Go Functions (Computed Fields & Custom Filters)\nAnansi allows registering custom Go functions to perform operations that are either too complex for standard SQL or operate on data after initial database retrieval (e.g., on JSON fields). These functions are managed by the `persistence.Executor`.\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n\t\"go.uber.org/zap\"\n)\n\n// Assume 'persistenceSvc' is an initialized *persistence.Persistence\n// and 'collection' is an initialized core.PersistenceCollectionInterface\nfunc useGoFunctions(persistenceSvc *persistence.Persistence, collection core.PersistenceCollectionInterface) {\n\t// Define a schema with a JSON 'metadata' field for demonstration\n\t// (This would typically be done during collection creation)\n\titemSchemaJSON := `{ \"name\": \"items\", \"version\": \"1.0.0\", \"fields\": { \"id\": {\"type\": \"integer\", \"unique\": true}, \"name\": {\"type\": \"string\", \"required\": true}, \"metadata\": {\"type\": \"object\"} }, \"indexes\": [{\"name\": \"pk_item_id\", \"fields\": [\"id\"], \"type\": \"primary\"}]}`\n\tvar itemSchema core.SchemaDefinition\n\t_ = json.Unmarshal([]byte(itemSchemaJSON), &itemSchema)\n\n\t// Register custom Go functions via the Executor within Persistence\n\tpersistenceSvc.RegisterComputeFunction(\"item_display\", func(row query.Document, args query.FilterValue) (any, error) {\n\t\tname, ok := row[\"name\"].(string)\n\t\tif !ok { return nil, fmt.Errorf(\"name is not a string\") }\n\t\tif metaRaw, ok := row[\"metadata\"].(string); ok { // Stored as JSON string\n\t\t\tvar metaMap map[string]any\n\t\t\tif err := json.Unmarshal([]byte(metaRaw), &metaMap); err == nil {\n\t\t\t\tif category, ok := metaMap[\"category\"].(string); ok { return fmt.Sprintf(\"%s (%s)\", name, category), nil }\n\t\t\t}\n\t\t}\n\t\treturn name, nil\n\t})\n\n\tpersistenceSvc.RegisterFilterFunction(\"is_heavy\", func(doc query.Document, field string, args query.FilterValue) (bool, error) {\n\t\tif metaRaw, ok := doc[\"metadata\"].(string); ok {\n\t\t\tvar metaMap map[string]any\n\t\t\tif err := json.Unmarshal([]byte(metaRaw), &metaMap); err == nil {\n\t\t\t\tif weight, ok := metaMap[\"weight_kg\"].(float64); ok { return weight > 1.5, nil }\n\t\t\t}\n\t\t}\n\t\treturn false, nil\n\t})\n\n\t// Insert sample data (assuming 'items' collection is created)\n\tcollection.Create(map[string]any{\"name\": \"Laptop\", \"metadata\": map[string]any{\"category\": \"electronics\", \"weight_kg\": 1.8}})\n\tcollection.Create(map[string]any{\"name\": \"Desk Chair\", \"metadata\": map[string]any{\"category\": \"furniture\", \"material\": \"mesh\"}})\n\n\t// Query using the registered compute function\n\tqWithComputed := query.NewQueryBuilder().\n\t\tSelect().\n\t\t\tInclude(\"id\", \"name\", \"metadata\"). // Base fields needed for compute function\n\t\t\tAddComputed(\"item_display_name\", \"item_display\"). // Use registered compute function\n\t\tEnd().\n\t\tBuild()\n\n\tresultComputed, err := collection.Read(qWithComputed)\n\tif err != nil { log.Fatalf(\"Failed to query with computed field: %v\", err) }\n\tfmt.Println(\"\\n--- Results with Computed Field ---\")\n\tfor _, r := range resultComputed.(*query.QueryResult).Data.([]query.Document) {\n\t\tfmt.Printf(\"ID: %v, Name: %v, Display: %v\\n\", r[\"id\"], r[\"name\"], r[\"item_display_name\"])\n\t}\n\n\t// Query using the custom Go filter\n\tqWithFilter := query.NewQueryBuilder().\n\t\tWhere(\"metadata\").Custom(\"is_heavy\", nil). // Use custom filter on 'metadata' field\n\t\tSelect().Include(\"id\", \"name\").End().Build()\n\n\tresultFilter, err := collection.Read(qWithFilter)\n\tif err != nil { log.Fatalf(\"Failed to query with custom filter: %v\", err) }\n\tfmt.Println(\"\\n--- Results with Custom Filter (heavy_item) ---\")\n\tfor _, r := range resultFilter.(*query.QueryResult).Data.([]query.Document) {\n\t\tfmt.Printf(\"ID: %v, Name: %v\\n\", r[\"id\"], r[\"name\"])\n\t}\n}\n```\n**Important Note on Go Functions**: Go-based filters and computed fields operate on data *after* it has been retrieved from the database. This means they are executed **in-memory**. For very large datasets, using highly selective SQL filters first is crucial for performance. Go functions are best suited for complex logic that cannot be expressed easily in SQL.\n\n### Transaction Management\nAnansi's `PersistenceInterface` provides a `Transact` method to execute a series of operations atomically within a database transaction.\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'persistenceSvc' is an initialized *persistence.Persistence\nfunc demonstrateTransaction(persistenceSvc *persistence.Persistence) {\n\t_, err := persistenceSvc.Transact(func(tx core.PersistenceTransactionInterface) (any, error) {\n\t\t// Get a transactional collection instance using the transaction interface\n\t\tusersTxCollection, err := tx.Collection(\"users\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to get transactional users collection: %w\", err)\n\t\t}\n\n\t\t// Perform operations within the transaction\n\t\t_, err = usersTxCollection.Create(map[string]any{\n\t\t\t\"name\":      \"Transaction User\",\n\t\t\t\"email\":     \"tx_user@example.com\",\n\t\t\t\"age\":       40,\n\t\t\t\"is_active\": true,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to create user in transaction: %w\", err)\n\t\t}\n\n\t\t// Simulate a failure to trigger rollback\n\t\t// return nil, fmt.Errorf(\"simulated error: rolling back transaction\")\n\n\t\tfmt.Println(\"Transaction operations successful.\")\n\t\treturn \"Transaction committed successfully!\", nil\n\t})\n\n\tif err != nil {\n\t\tfmt.Printf(\"Transaction failed: %v\\n\", err)\n\t} else {\n\t\tfmt.Println(\"Transaction completed without error.\")\n\t}\n}\n```\n\n### Event Subscriptions\nAnansi emits various events during persistence operations. You can subscribe to these events for auditing, reactive programming, or custom logging.\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc subscribeToEvents(collection core.PersistenceCollectionInterface) {\n\t// Register a subscription for DocumentCreateSuccess events\n\tsubscriptionID := collection.RegisterSubscription(core.RegisterSubscriptionOptions{\n\t\tEvent: core.DocumentCreateSuccess,\n\t\tCallback: func(ctx context.Context, event core.PersistenceEvent) error {\n\t\t\tfmt.Printf(\"➡️ New document created in collection '%s': %v\\n\", *event.Collection, event.Output)\n\t\t\treturn nil\n\t\t},\n\t\tLabel:       core.StringPtr(\"log_new_document\"),\n\t\tDescription: core.StringPtr(\"Logs details of newly created documents.\"),\n\t})\n\tfmt.Printf(\"Subscribed to DocumentCreateSuccess with ID: %s\\n\", subscriptionID)\n\n\t// Now, when you create a document, the callback will be triggered:\n\t_, err := collection.Create(map[string]any{\n\t\t\"name\":      \"Event User\",\n\t\t\"email\":     \"event.user@example.com\",\n\t\t\"age\":       22,\n\t\t\"is_active\": true,\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to create event user: %v\", err)\n\t}\n\n\t// You can unregister subscriptions by their ID\n\t// collection.UnregisterSubscription(subscriptionID)\n}\n```",
      "agentGuidance": {
        "decisionPoints": [
          "IF [user requires complex data retrieval or manipulation] THEN [use query.QueryBuilder to define a QueryDSL].",
          "IF [user needs custom logic not expressible in SQL (e.g., JSON field parsing, domain-specific calculations)] THEN [register Go functions (ComputeFunction or PredicateFunction) with persistence.Persistence and use them in QueryDSL].",
          "IF [user needs atomic operations across multiple data manipulations] THEN [wrap operations in persistence.Persistence.Transact()].",
          "IF [user needs to react to data changes or system events (e.g., auditing, real-time updates)] THEN [register a subscription with collection.RegisterSubscription()]."
        ],
        "verificationSteps": [
          "Check: `query.NewQueryBuilder()...Build()` syntax results in valid `QueryDSL`.",
          "Check: For Go functions, ensure functions are registered correctly and required fields are included in projection.",
          "Check: Transaction success/failure by observing changes in the database and the return value/error of `Transact`.",
          "Check: Event subscription by observing logs or side effects from the callback function."
        ],
        "quickPatterns": [
          "Pattern: Advanced Querying\n```go\nqueryDSL := query.NewQueryBuilder().Where(\"field\").Gt(10).OrderByAsc(\"anotherField\").Limit(5).Build()\nresults, err := collection.Read(queryDSL)\n```",
          "Pattern: Register Computed Field\n```go\npersistenceSvc.RegisterComputeFunction(\"myComputedField\", func(row query.Document, args query.FilterValue) (any, error) { /* ... logic ... */ return \"\", nil })\nquery := query.NewQueryBuilder().Select().AddComputed(\"myAlias\", \"myComputedField\").End().Build()\n```",
          "Pattern: Transaction Block\n```go\n_, err := persistenceSvc.Transact(func(tx core.PersistenceTransactionInterface) (any, error) {\n    txCollection, _ := tx.Collection(\"mycollection\")\n    // ... transactional ops ...\n    return nil, nil\n})\n```",
          "Pattern: Subscribe to Document Creation\n```go\ncollection.RegisterSubscription(core.RegisterSubscriptionOptions{\n    Event: core.DocumentCreateSuccess,\n    Callback: func(ctx context.Context, event core.PersistenceEvent) error { /* ... handle event ... */ return nil },\n})\n```"
        ],
        "diagnosticPaths": [
          "Error `unregistered Go compute function` -> Symptom: Computed field or custom filter not found during query execution -> Check: Ensure the function name used in `AddComputed` or `Custom` matches the name used in `RegisterComputeFunction`/`RegisterFilterFunction`. -> Fix: Correct the function name or ensure registration happens before the query.",
          "Error `Transaction failed: Cannot start a new transaction from an existing transactional interactor` -> Symptom: Attempting to start nested transactions incorrectly -> Check: Only call `StartTransaction` on a non-transactional interactor. The `Transact` helper already manages this. -> Fix: Refactor transaction logic to use the `Transact` helper or manage interactor instances carefully.",
          "Error `Failed to read data with advanced query` -> Symptom: Complex query fails -> Check: Validate the `QueryDSL` structure using `query.QueryBuilder.Validate()` for common errors. Examine SQL query and parameters logged by `zap` for issues. -> Fix: Adjust `QueryDSL` or debug SQL generation."
        ]
      }
    },
    {
      "title": "Advanced Usage",
      "path": "advanced-usage.md",
      "content": "Anansi's architecture is designed for modularity and extensibility, allowing advanced users to customize and optimize its behavior.\n\n### Project Architecture\nAnansi is structured to separate core persistence concepts from their concrete database implementations. Key packages include:\n\n*   **`core/`**: Defines foundational abstractions: `SchemaDefinition` (data models), `PersistenceInterface` & `PersistenceCollectionInterface` (high-level APIs), `DatabaseInteractor` (DB-agnostic low-level CRUD), `QueryDSL` (declarative queries), `Validator`.\n*   **`sqlite/`**: Provides concrete implementations for SQLite: `SQLiteInteractor` (implements `DatabaseInteractor`), `SqliteQueryGeneratorFactory` & `SqliteQuery` (implement `QueryGenerator` for SQLite-specific SQL).\n*   **`persistence/`**: Orchestrates `DatabaseInteractor` and `QueryGenerator` to provide the main `Persistence` and `PersistenceCollection` APIs, handling schema storage, execution, and event emission.\n\n#### Data Flow for Queries (`collection.Read`)\n1.  User constructs a `query.QueryDSL` using `query.NewQueryBuilder()`.\n2.  `PersistenceCollection.Read()` receives the `QueryDSL` and delegates to `persistence.Executor`.\n3.  `Executor` determines required fields (for SQL and Go functions).\n4.  `Executor` uses `DatabaseInteractor`'s `QueryGenerator` (e.g., `sqlite.SqliteQuery`) to translate SQL-executable parts of `QueryDSL` into SQL string and parameters.\n5.  `DatabaseInteractor` executes the SQL query against `sql.DB`/`sql.Tx`.\n6.  Retrieved rows are converted into `query.Document` (map[string]any), performing schema-aware type conversions.\n7.  **Post-SQL Processing**: `persistence.Executor` applies any registered **Go-based filter functions** and **Go-based computed field functions** on these in-memory `query.Document` objects via `query.DataProcessor`.\n8.  `query.DataProcessor` applies final projection (include/exclude fields).\n9.  Processed `query.QueryResult` is returned.\n\n### Customization and Optimization\n#### Extension Points\nAnansi is designed for extensibility through its interfaces:\n\n*   **`persistence.DatabaseInteractor`**: Implement this interface to add support for a new database (e.g., PostgreSQL, MySQL). It defines how schemas are mapped to DDL and how basic CRUD operations and transactions are performed.\n*   **`query.QueryGeneratorFactory` & `query.QueryGenerator`**: Implement these to define how `query.QueryDSL` objects are transformed into database-specific SQL queries for a new database dialect.\n*   **`core.FunctionMap`**: Register custom Go functions (as `query.ComputeFunction` and `query.PredicateFunction`) at `persistence.NewPersistence` initialization to extend querying capabilities with in-memory logic. This is crucial for complex calculations or operations on semi-structured data that cannot be efficiently handled by native SQL.\n\n#### Static Type Mapping & Code Generation (Planned Enhancement)\nAnansi plans to introduce optional static type mapping, allowing generation of Go structs from `SchemaDefinition`s. This will provide compile-time safety and improved developer experience while maintaining the flexibility of schema-driven development. This feature aims to bridge the gap between dynamic schema-first approaches and traditional static ORM patterns.\n\n**Planned Functionality:**\n*   **Automatic Struct Generation**: Generate Go structs from your schema definitions.\n*   **Reflection-Based Mapping**: Seamlessly convert between `query.Document` results and strongly-typed structs.\n*   **Dual Interface Support**: Continue supporting both `map[string]any` and strongly-typed struct approaches.\n\nThis will offer the best of both worlds: runtime schema evolution with compile-time type safety."
    },
    {
      "title": "Problem Solving",
      "path": "problem-solving.md",
      "content": "This section covers common issues and provides diagnostic and resolution paths.\n\n### Troubleshooting\n\n*   **`database/sql: unknown driver \"sqlite3\"`**:\n    *   **Symptom**: Application fails to open database connection with an unknown driver error.\n    *   **Check**: Ensure you have imported the SQLite driver with a blank import: `_ \"github.com/mattn/go-sqlite3\"`.\n    *   **Fix**: Add `_ \"github.com/mattn/go-sqlite3\"` to your import statements.\n\n*   **`... not found: [database/sqlite3]` or similar build errors related to SQLite C library**:\n    *   **Symptom**: Go build or run commands fail, indicating a missing SQLite C library.\n    *   **Check**: Verify if the SQLite C library is installed on your system and accessible by the Go toolchain.\n    *   **Fix**:\n        *   **Linux (Debian/Ubuntu)**: `sudo apt-get install sqlite3 libsqlite3-dev`\n        *   **Linux (RHEL/CentOS)**: `sudo yum install sqlite-devel`\n        *   **macOS**: SQLite3 is usually pre-installed. If not, try `brew install sqlite`.\n        *   **Windows**: This can be complex. You might need to install MSYS2 and then `pacman -S mingw-w64-x86_64-sqlite3`, ensuring your Go environment uses the `mingw-w64` toolchain.\n\n*   **`SQL logic error or missing database INSERT ... RETURNING`**:\n    *   **Symptom**: Insert operations fail with a SQL error related to `RETURNING` clause.\n    *   **Check**: Your SQLite version might be too old. The `RETURNING` clause requires SQLite version `3.35.0` or newer.\n    *   **Fix**: Upgrade your SQLite installation to version 3.35.0 or newer.\n\n*   **`Cannot start a new transaction from an existing transactional interactor`**:\n    *   **Symptom**: An error occurs when attempting to initiate a new transaction from an `SQLiteInteractor` instance that is already part of an ongoing transaction.\n    *   **Check**: The `StartTransaction` method on `SQLiteInteractor` is designed to be called only on a non-transactional instance (`e.tx` is `nil`). When you call `StartTransaction`, it returns a *new* `SQLiteInteractor` instance that is bound to the new transaction. The original instance remains non-transactional.\n    *   **Fix**: Ensure you are calling `StartTransaction` on the base, non-transactional `persistence.DatabaseInteractor` (or `SQLiteInteractor`) instance. If using `persistence.Persistence.Transact`, this is handled automatically.\n\n### Error Reference\nAnansi provides detailed error messages to aid in debugging. Below are common error scenarios and their typical solutions.\n\n*   **Code**: `REQUIRED_FIELD_MISSING`\n    *   **Symptom**: A document creation or update fails because a field marked as `\"required\": true` in the schema is missing or explicitly `nil` in the input data.\n    *   **Check**: Examine your `core.SchemaDefinition` for the collection and the input `map[string]any` to identify the missing field.\n    *   **Fix**: Provide a value for the required field in the input data.\n\n*   **Code**: `TYPE_MISMATCH`\n    *   **Symptom**: A field's value does not match the `\"type\"` defined in the schema (e.g., providing a string for an `\"integer\"` field).\n    *   **Check**: Compare the actual type of the value with the `FieldType` specified in the schema for that field.\n    *   **Fix**: Ensure data types align with schema definitions. Anansi attempts some basic type coercion (e.g., \"true\" to `true`), but strict mismatches will fail.\n\n*   **Code**: `CONSTRAINT_VIOLATION` / `CONSTRAINT_GROUP_VIOLATION`\n    *   **Symptom**: A document fails validation against a custom `\"constraint\"` or a group of constraints defined in the schema (e.g., an enum value is not in the `\"values\"` list, or a custom predicate function returns `false`).\n    *   **Check**: Review the `\"constraints\"` section in your schema and the logic of any custom predicate functions registered in your `core.FunctionMap`.\n    *   **Fix**: Adjust the data to satisfy the constraint or modify the constraint/predicate logic if it's too restrictive.\n\n*   **Error**: `Failed to unmarshal user schema JSON`\n    *   **Symptom**: Application crashes during schema loading from JSON string.\n    *   **Check**: Verify the `userSchemaJSON` string is valid JSON and conforms to the `core.SchemaDefinition` struct's expected format.\n    *   **Fix**: Use a JSON linter or validator to check your schema JSON string.\n\n*   **Error**: `A collection with a similar name exists`\n    *   **Symptom**: Attempting to create a collection with a name that already exists in the database's `_schemas` collection.\n    *   **Check**: Call `persistence.Persistence.CollectionExists()` or `persistence.Persistence.Collections()` to see existing collections.\n    *   **Fix**: Choose a unique name for the new collection, or drop the existing collection if it's no longer needed.\n\n*   **Error**: `Collection X does not exist`\n    *   **Symptom**: Attempting to retrieve a `PersistenceCollectionInterface` for a non-existent collection.\n    *   **Check**: Ensure the collection name passed to `persistence.Persistence.Collection()` matches an existing collection.\n    *   **Fix**: Create the collection using `persistence.Persistence.Create()` first, or correct the collection name.\n\n*   **Error**: `unregistered Go filter function` / `unregistered Go compute function`\n    *   **Symptom**: A query using `Custom` filter operator or `AddComputed` projection fails because the referenced Go function is not found.\n    *   **Check**: Verify that the function with the given name (e.g., `\"is_heavy\"` or `\"item_display\"`) was registered using `persistenceSvc.RegisterFilterFunction()` or `persistenceSvc.RegisterComputeFunction()` during setup.\n    *   **Fix**: Ensure the Go function is correctly registered with the `persistence.Persistence` instance before executing queries that rely on it.\n\n*   **Error**: `DELETE without WHERE clause is not allowed for safety.`\n    *   **Symptom**: Attempting to call `collection.Delete(nil, false)` (or `collection.Delete(filter, false)` with `filter` being `nil`).\n    *   **Check**: Anansi prevents accidental full table deletes. A `QueryFilter` is mandatory by default.\n    *   **Fix**: Provide a valid `QueryFilter` to narrow down the deletion, or explicitly set `unsafe` to `true` (e.g., `collection.Delete(nil, true)`) to indicate intent to delete all records. Use `unsafe: true` with extreme caution in production environments.\n\n*   **Error**: `failed to generate SQL query` / `failed to execute SELECT query` (or similar for UPDATE/INSERT/DELETE)\n    *   **Symptom**: Database operation fails at the SQL generation or execution stage.\n    *   **Check**: These are often wrapped errors from the underlying SQL driver. Examine the full error message for details. Turn on `zap.NewDevelopment()` logger for more verbose SQL query and parameter logging, which can reveal issues with SQL syntax or parameter binding.\n    *   **Fix**: If it's a SQL syntax issue, review the generated SQL (`zap` logger output). If it's a parameter issue, check the types and values of your `query.QueryDSL` or `map[string]any` inputs. Database connection issues could also manifest here."
    },
    {
      "title": "Reference",
      "path": "reference.md",
      "content": ""
    }
  ],
  "reference": {
    "system": {
      "name": "Anansi (Go Implementation)",
      "language": "Go",
      "description": "Anansi is a comprehensive Go framework for schema-driven data persistence, enabling declarative data modeling, flexible querying, and adaptable storage layers.",
      "keyFeatures": [
        "Schema-Driven Data Modeling",
        "Pluggable Persistence Layer",
        "Declarative Query DSL",
        "In-memory Go Function Processing",
        "Transaction Management",
        "Event-Driven Architecture",
        "Runtime Data Validation"
      ]
    },
    "dependencies": {
      "external": [
        {
          "name": "github.com/mattn/go-sqlite3",
          "purpose": "SQLite database driver for Go.",
          "interfaces": [
            {
              "name": "database/sql.Driver",
              "description": "Go's standard interface for database drivers. Implements `Open()` to return `database/sql.Conn`.",
              "methods": []
            }
          ],
          "installation": "go get github.com/mattn/go-sqlite3",
          "version": ">=1.14.0"
        },
        {
          "name": "go.uber.org/zap",
          "purpose": "Structured, leveled logging for Go applications.",
          "interfaces": [
            {
              "name": "zap.Logger",
              "description": "Core logger for structured logging. Methods like `Debug`, `Info`, `Error` log messages with structured fields.",
              "methods": [
                {
                  "name": "Debug",
                  "signature": "func (l *Logger) Debug(msg string, fields ...Field)",
                  "parameters": "msg: string - The message to log. fields: ...Field - Zero or more `zap.Field`s (e.g., `zap.String(\"key\", \"value\")`) for structured context.",
                  "returnValue": "None"
                },
                {
                  "name": "Info",
                  "signature": "func (l *Logger) Info(msg string, fields ...Field)",
                  "parameters": "msg: string - The message to log. fields: ...Field - Zero or more `zap.Field`s for structured context.",
                  "returnValue": "None"
                },
                {
                  "name": "Error",
                  "signature": "func (l *Logger) Error(msg string, fields ...Field)",
                  "parameters": "msg: string - The message to log. fields: ...Field - Zero or more `zap.Field`s for structured context.",
                  "returnValue": "None"
                }
              ]
            }
          ],
          "installation": "go get go.uber.org/zap",
          "version": ">=1.20.0"
        },
        {
          "name": "github.com/google/uuid",
          "purpose": "Generates universally unique identifiers (UUIDs) for various purposes.",
          "interfaces": [],
          "installation": "go get github.com/google/uuid",
          "version": ">=1.3.0"
        },
        {
          "name": "github.com/asaidimu/go-events",
          "purpose": "A type-safe event bus for Go, used internally for event emission and subscriptions.",
          "interfaces": [
            {
              "name": "events.TypedEventBus[T]",
              "description": "A generic event bus that allows publishing and subscribing to events of a specific type `T`.",
              "methods": [
                {
                  "name": "NewTypedEventBus",
                  "signature": "func NewTypedEventBus[T any](config events.Config) (*TypedEventBus[T], error)",
                  "parameters": "config: events.Config - Configuration options for the event bus.",
                  "returnValue": "(*TypedEventBus[T], error) - A new event bus instance or an error."
                },
                {
                  "name": "Emit",
                  "signature": "func (b *TypedEventBus[T]) Emit(eventName string, payload T)",
                  "parameters": "eventName: string - The name of the event to emit. payload: T - The event payload.",
                  "returnValue": "None"
                },
                {
                  "name": "Subscribe",
                  "signature": "func (b *TypedEventBus[T]) Subscribe(eventName string, callback func(T)) func()",
                  "parameters": "eventName: string - The event name to subscribe to. callback: func(T) - The function to call when the event is emitted.",
                  "returnValue": "func() - An unsubscribe function."
                }
              ]
            }
          ],
          "installation": "go get github.com/asaidimu/go-events",
          "version": "^0.0.1"
        }
      ],
      "peer": [
        {
          "name": "database/sql",
          "reason": "Required for general database interaction (connections, transactions, queries) in Go applications.",
          "version": "Go standard library"
        },
        {
          "name": "context",
          "reason": "Required for managing request-scoped values, cancellation signals, and deadlines across API boundaries.",
          "version": "Go standard library"
        },
        {
          "name": "encoding/json",
          "reason": "Required for marshaling/unmarshaling Go structs to/from JSON, used extensively for schema definitions and data interchange.",
          "version": "Go standard library"
        },
        {
          "name": "fmt",
          "reason": "Required for formatted I/O operations, particularly for error messages and logging.",
          "version": "Go standard library"
        },
        {
          "name": "log",
          "reason": "Basic logging capabilities for simple output, though `zap` is preferred for structured logging.",
          "version": "Go standard library"
        },
        {
          "name": "os",
          "reason": "Required for operating system interactions, such as file removal for database initialization.",
          "version": "Go standard library"
        },
        {
          "name": "strings",
          "reason": "Required for string manipulation, used in SQL generation and path building.",
          "version": "Go standard library"
        },
        {
          "name": "sync",
          "reason": "Required for synchronization primitives like mutexes to protect shared data structures (e.g., event bus subscriptions).",
          "version": "Go standard library"
        },
        {
          "name": "strconv",
          "reason": "Required for converting strings to numeric types and vice versa, used in validation and type coercion.",
          "version": "Go standard library"
        },
        {
          "name": "reflect",
          "reason": "Required for runtime reflection, used in validator for type checking and comparisons.",
          "version": "Go standard library"
        },
        {
          "name": "maps",
          "reason": "Required for map manipulation, such as copying map contents in projection logic.",
          "version": "Go standard library (Go 1.21+)"
        }
      ]
    },
    "integration": {
      "environmentRequirements": "Requires Go 1.24.4 or newer. For SQLite integration, the underlying SQLite C library must be installed on the system where the application runs. (e.g., `libsqlite3-dev` on Linux, `sqlite` on macOS via Homebrew).",
      "initializationPatterns": [
        {
          "description": "Standard pattern for initializing the Anansi persistence service with a SQLite database. This involves opening an `sql.DB` connection, creating a `sqlite.SQLiteInteractor`, and then instantiating the core `persistence.Persistence` service.",
          "codeExample": "package main\n\nimport (\n\t\"database/sql\"\n\t\"log\"\n\t\"os\"\n\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n\t\"github.com/asaidimu/go-anansi/sqlite\"\n\t_ \"github.com/mattn/go-sqlite3\" // SQLite driver\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Clean up previous database for fresh start\n\tif err := os.Remove(\"my_app.db\"); err != nil && !os.IsNotExist(err) {\n\t\tlog.Fatalf(\"Failed to remove existing database file: %v\", err)\n\t}\n\n\t// Open database connection\n\tdb, err := sql.Open(\"sqlite3\", \"my_app.db\")\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to open database connection: %v\", err)\n\t}\n\tdefer func() {\n\t\tif cErr := db.Close(); cErr != nil {\n\t\t\tlog.Printf(\"Error closing database connection: %v\", cErr)\n\t\t}\n\t}()\n\n\t// Initialize logger (Nop for silent, Development for verbose)\n\tlogger := zap.NewNop()\n\n\t// Create SQLite interactor\n\tinteractor := sqlite.NewSQLiteInteractor(db, logger, nil, nil) // (db, logger, options, tx)\n\n\t// Initialize Anansi Persistence service\n\tpersistenceSvc, err := persistence.NewPersistence(interactor, core.FunctionMap{})\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to initialize persistence: %v\", err)\n\t}\n\tlog.Println(\"Anansi Persistence initialized successfully.\")\n\n\t// Your application logic follows...\n}\n"
        }
      ],
      "commonPitfalls": [
        {
          "issue": "Missing SQLite C library causing build or runtime errors.",
          "solution": "Ensure `libsqlite3-dev` (Linux), `sqlite` (macOS), or a proper MSYS2 setup (Windows) is configured. Verify `_ \"github.com/mattn/go-sqlite3\"` import."
        },
        {
          "issue": "Old SQLite version (`<3.35.0`) leading to `RETURNING *` SQL errors.",
          "solution": "Upgrade SQLite installation to a version that supports the `RETURNING` clause."
        },
        {
          "issue": "Attempting to call transactional methods on a non-transactional interactor, or vice-versa.",
          "solution": "Use `persistence.Persistence.Transact()` for higher-level transaction management, or explicitly manage interactor instances returned by `StartTransaction()`."
        }
      ],
      "lifecycleDependencies": "The `persistence.Persistence` service depends on an initialized `sql.DB` connection. This connection should be opened early in the application's lifecycle and closed gracefully, typically using `defer db.Close()` in `main()`. Transactions are managed by the `DatabaseInteractor`, where `StartTransaction()` returns a new, transaction-bound interactor instance. This transactional instance must be `Commit()`ed or `Rollback()`ed before its scope ends. Schemas are stored and managed internally by Anansi within a special `_schemas` collection upon `persistence.NewPersistence`."
    },
    "types": {
      "SchemaDefinition": {
        "id": "type:SchemaDefinition",
        "definition": "type SchemaDefinition struct {\n    Name        string\n    Version     string\n    Description *string\n    Fields      map[string]*FieldDefinition\n    NestedSchemas map[string]*NestedSchemaDefinition\n    Indexes       []IndexDefinition\n    Constraints   SchemaConstraint[FieldType]\n    Metadata      map[string]any\n    Migrations    []Migration[any]\n    Hint          *SchemaHint\n    Mock func(faker any) (any, error) `json:\"-\"`\n}",
        "purpose": "Defines the structure and constraints of a data collection (table). It's the core declarative model for Anansi.",
        "related": {
          "methods": [
            "method:persistence.Persistence.Create",
            "method:persistence.Persistence.Schema",
            "method:sqlite.SQLiteInteractor.CreateCollection",
            "method:core.Validator.Validate"
          ],
          "patterns": [
            "pattern:Defining Schemas",
            "pattern:Collection Creation"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Fields": "map[string]*FieldDefinition - Defines individual fields within the schema. Required.",
            "NestedSchemas": "map[string]*NestedSchemaDefinition - Reusable definitions for complex nested objects.",
            "Indexes": "[]IndexDefinition - Defines database indexes for performance or uniqueness.",
            "Constraints": "SchemaConstraint[FieldType] - Global validation rules applied to the entire document.",
            "Metadata": "map[string]any - Arbitrary metadata for the schema."
          }
        }
      },
      "FieldDefinition": {
        "id": "type:FieldDefinition",
        "definition": "type FieldDefinition struct {\n    Name string\n    Type FieldType\n    Required *bool\n    Constraints SchemaConstraint[FieldType]\n    Default any\n    Values []any\n    Schema any\n    ItemsType *FieldType\n    Deprecated *bool\n    Description *string\n    Unique *bool\n    Hint *struct { Input InputHint }\n}",
        "purpose": "Describes a single field within a `SchemaDefinition`, including its type, constraints, and nested schema references.",
        "related": {
          "methods": [
            "method:sqlite.SQLiteInteractor.buildColumnDefinition",
            "method:sqlite.SQLiteInteractor.GetColumnType",
            "method:core.Validator.validateFieldValue"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Name": "string - The name of the field.",
            "Type": "FieldType - The data type of the field (e.g., \"string\", \"integer\", \"object\").",
            "Required": "*bool - If true, the field must be present and non-null.",
            "Default": "any - A default value for the field.",
            "Values": "[]any - For `FieldTypeEnum`, a list of allowed values.",
            "Schema": "any - For complex types (`object`, `union`), defines the nested schema structure. Can be `FieldSchema` or `[]FieldSchema`.",
            "ItemsType": "*FieldType - For `array` or `set` types, specifies the type of elements within the array/set.",
            "Unique": "*bool - If true, values in this field must be unique across all documents in the collection."
          }
        }
      },
      "IndexDefinition": {
        "id": "type:IndexDefinition",
        "definition": "type IndexDefinition struct {\n    Fields []string\n    Type IndexType\n    Unique *bool\n    Partial *PartialIndexCondition\n    Description *string\n    Order *string\n    Name string\n}",
        "purpose": "Defines a database index for optimizing queries and enforcing uniqueness constraints.",
        "related": {
          "methods": [
            "method:sqlite.SQLiteInteractor.CreateIndex",
            "method:sqlite.SQLiteInteractor.CreateIndexSQL"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Fields": "[]string - The list of field names to include in the index.",
            "Type": "IndexType - The type of index (e.g., \"primary\", \"unique\", \"normal\").",
            "Name": "string - The unique name of the index."
          }
        }
      },
      "NestedSchemaDefinition": {
        "id": "type:NestedSchemaDefinition",
        "definition": "type NestedSchemaDefinition struct {\n    Name        string\n    Description *string\n    Indexes     []IndexDefinition\n    Metadata    map[string]any\n    Concrete    *bool\n    Type               *FieldType\n    LiteralConstraints SchemaConstraint[FieldType]\n    LiteralDefault     any\n    LiteralSchema      any\n    LiteralItemsType   *FieldType\n    StructuredFieldsMap   map[string]*FieldDefinition\n    StructuredFieldsArray []struct { Fields map[string]*FieldDefinition; When *struct { Field string; Value any }}\n}",
        "purpose": "Represents a reusable, self-contained schema structure that can be embedded within other `SchemaDefinition`s as a complex field type.",
        "related": {
          "methods": [
            "method:core.Validator.validateFieldSchema"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Name": "string - The unique identifier for this nested schema.",
            "Type": "*FieldType - (Optional) If defined, this nested schema represents a primitive literal type (e.g., string, number) with its own constraints.",
            "StructuredFieldsMap": "map[string]*FieldDefinition - (Optional) If defined, this nested schema represents a structured object with named fields.",
            "StructuredFieldsArray": "[]struct{...} - (Optional) If defined, this represents a structured object with conditional fields based on a `When` clause."
          }
        }
      },
      "PersistenceEvent": {
        "id": "type:PersistenceEvent",
        "definition": "type PersistenceEvent struct {\n    Type          PersistenceEventType\n    Timestamp     int64\n    Operation     string\n    Collection    *string\n    Input         any\n    Output        any\n    Error         *string\n    Issues        []Issue\n    Query         any\n    TransactionID *string\n    Duration      *int64\n    Context       map[string]any\n}",
        "purpose": "Represents an event emitted during a persistence operation, providing comprehensive context about the operation's type, status, and associated data.",
        "related": {
          "methods": [
            "method:persistence.Collection.emitEvent",
            "method:persistence.Collection.withEventEmission",
            "method:persistence.Collection.RegisterSubscription"
          ],
          "patterns": [
            "pattern:Event Subscription"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "PersistenceEventType - The specific type of event (e.g., `document:create:success`).",
            "Timestamp": "int64 - Unix milliseconds timestamp of the event.",
            "Operation": "string - The category of operation (e.g., `create`, `read`, `update`).",
            "Collection": "*string - The name of the collection affected, if applicable.",
            "Input": "any - The input data provided to the operation.",
            "Output": "any - The output/result of the operation.",
            "Error": "*string - An error message if the operation failed.",
            "Issues": "[]Issue - A list of validation or operational issues.",
            "Query": "any - The query object used (typically `query.QueryDSL` or `query.QueryFilter`).",
            "Duration": "*int64 - The duration of the operation in milliseconds."
          }
        }
      },
      "PersistenceEventType": {
        "id": "type:PersistenceEventType",
        "definition": "type PersistenceEventType string",
        "purpose": "Enumerates distinct types of events that can be emitted by the Anansi persistence layer.",
        "related": {
          "methods": [
            "method:persistence.Collection.RegisterSubscription"
          ],
          "patterns": [
            "pattern:Event Subscription"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {}
        }
      },
      "Issue": {
        "id": "type:Issue",
        "definition": "type Issue struct {\n    Code        string\n    Message     string\n    Path        string\n    Severity    string\n    Description string\n}",
        "purpose": "Represents a single validation or operational issue encountered during processing, providing a structured error message.",
        "related": {
          "methods": [
            "method:core.Validator.Validate",
            "method:core.Validator.addIssue"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Code": "string - A specific error code (e.g., `REQUIRED_FIELD_MISSING`).",
            "Message": "string - A human-readable error message.",
            "Path": "string - The path to the field or element causing the issue (e.g., `user.address.city`).",
            "Severity": "string - The severity level (e.g., `error`, `warning`)."
          }
        }
      },
      "MetadataFilter": {
        "id": "type:MetadataFilter",
        "definition": "type MetadataFilter struct {\n    Subscriptions *struct { Event *json.RawMessage; Label *string }\n    Triggers *struct { Event *json.RawMessage; Label *string }\n    Tasks *struct { ID *string; Metadata map[string]any; Label *string }\n    Schemas *struct { ID *string }\n}",
        "purpose": "Defines criteria for filtering and retrieving various types of metadata (subscriptions, triggers, tasks, schemas) from the persistence layer.",
        "related": {
          "methods": [
            "method:persistence.Persistence.Metadata",
            "method:persistence.Collection.Metadata"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Subscriptions": "Filters for registered subscriptions by event type or label.",
            "Triggers": "Filters for registered triggers by event pattern or label.",
            "Tasks": "Filters for registered tasks by ID, metadata, or label.",
            "Schemas": "Filters for schemas by ID (name)."
          }
        }
      },
      "Metadata": {
        "id": "type:Metadata",
        "definition": "type Metadata struct {\n    CollectionCount   *int64\n    StorageUsageBytes *int64\n    ConnectionStatus  *string\n    ConnectionError   *string\n    Schemas           []SchemaDefinition\n    Collections       []CollectionMetadata\n    Subscriptions     []SubscriptionInfo\n    Triggers          []TriggerInfo\n    Tasks             []TaskInfo\n    RecordCount   *int64\n    DataSizeBytes *int64\n    Schema        *SchemaDefinition\n    LastModified  *int64\n}",
        "purpose": "Aggregates various metadata information about the persistence system, including collection counts, schema definitions, and registered events/tasks.",
        "related": {
          "methods": [
            "method:persistence.Persistence.Metadata",
            "method:persistence.Collection.Metadata"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "CollectionCount": "*int64 - Total number of collections.",
            "StorageUsageBytes": "*int64 - Total storage consumed by all collections.",
            "ConnectionStatus": "*string - Current connection status of the database.",
            "Schemas": "[]SchemaDefinition - List of all registered schema definitions.",
            "Collections": "[]CollectionMetadata - Detailed metadata for each collection.",
            "Subscriptions": "[]SubscriptionInfo - List of all active global subscriptions.",
            "Triggers": "[]TriggerInfo - List of all active global triggers.",
            "Tasks": "[]TaskInfo - List of all active global tasks."
          }
        }
      },
      "CollectionUpdate": {
        "id": "type:CollectionUpdate",
        "definition": "type CollectionUpdate struct {\n    Data   map[string]any\n    Filter any\n}",
        "purpose": "A parameter object used for `Update` operations on a collection, specifying the fields to update and the criteria for selecting documents.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.Update",
            "method:persistence.Collection.Update",
            "method:persistence.Executor.Update"
          ],
          "patterns": [
            "pattern:Update Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Data": "map[string]any - A map of field names to their new values to be applied to matching documents.",
            "Filter": "any - A `*query.QueryFilter` specifying which documents to update. Required."
          }
        }
      },
      "ValidationResult": {
        "id": "type:ValidationResult",
        "definition": "type ValidationResult struct {\n    Valid  bool\n    Issues []Issue\n}",
        "purpose": "Encapsulates the outcome of a data validation process, indicating whether the data is valid and providing a list of any detected issues.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.Validate",
            "method:persistence.Collection.Validate",
            "method:core.Validator.Validate"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Valid": "bool - True if validation passed, false otherwise.",
            "Issues": "[]Issue - A slice of `Issue` structs detailing any validation failures."
          }
        }
      },
      "RegisterSubscriptionOptions": {
        "id": "type:RegisterSubscriptionOptions",
        "definition": "type RegisterSubscriptionOptions struct {\n    Event       PersistenceEventType\n    Label       *string\n    Description *string\n    Callback    CallbackFunction\n}",
        "purpose": "Options for registering a new event subscription, specifying the event type, an optional label, description, and the callback function.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.RegisterSubscription",
            "method:persistence.Collection.RegisterSubscription"
          ],
          "patterns": [
            "pattern:Event Subscription"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Event": "PersistenceEventType - The specific event type to subscribe to.",
            "Label": "*string - An optional short identifier for the subscription.",
            "Description": "*string - An optional detailed description of the subscription's purpose.",
            "Callback": "CallbackFunction - The function to be executed when the specified event occurs. Signature: `func(ctx context.Context, event PersistenceEvent) error`."
          }
        }
      },
      "TriggerInfo": {
        "id": "type:TriggerInfo",
        "definition": "type TriggerInfo struct {\n    Event       json.RawMessage\n    Condition   any\n    CallbackID  string\n    IsSync      bool\n    Label       string\n    Description string\n}",
        "purpose": "Describes a registered trigger's configuration, including the event it listens for, its condition, and metadata.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.RegisterTrigger",
            "method:persistence.Collection.RegisterTrigger"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Event": "json.RawMessage - The event(s) or event pattern that activates the trigger (e.g., `\"document:create:*\"`). Can be a string or array of strings.",
            "Condition": "any - An optional `query.QueryFilter` that must be met for the trigger to fire.",
            "CallbackID": "string - A unique identifier for the trigger's callback.",
            "IsSync": "bool - If true, the trigger's callback executes synchronously with the triggering operation, potentially affecting its outcome.",
            "Label": "string - A short, human-readable identifier for the trigger.",
            "Description": "string - A detailed description of the trigger's purpose."
          }
        }
      },
      "TaskInfo": {
        "id": "type:TaskInfo",
        "definition": "type TaskInfo struct {\n    ID          string\n    Schedule    TaskSchedule\n    CallbackID  string\n    IsSync      bool\n    Metadata    map[string]any\n    Label       string\n    Description string\n}",
        "purpose": "Describes a scheduled background task's configuration, including its schedule, callback, and metadata.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.RegisterTask",
            "method:persistence.Collection.RegisterTask"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "ID": "string - Unique identifier for the task.",
            "Schedule": "TaskSchedule - Defines when the task should run (cron, at, interval).",
            "CallbackID": "string - Unique identifier for the task's callback logic.",
            "IsSync": "bool - If true, the task executes synchronously (uncommon for scheduled tasks).",
            "Label": "string - Short identifier.",
            "Description": "string - Description of the task's purpose."
          }
        }
      },
      "TaskSchedule": {
        "id": "type:TaskSchedule",
        "definition": "type TaskSchedule struct {\n    Cron     *string\n    At       *string\n    Interval *int64\n}",
        "purpose": "Defines the scheduling parameters for a `TaskInfo`, allowing specification via cron expression, a specific timestamp, or a recurring interval.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.RegisterTask"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Cron": "*string - A cron expression (e.g., `\"0 0 * * *\"` for daily at midnight).",
            "At": "*string - An ISO 8601 timestamp for a one-time execution.",
            "Interval": "*int64 - A duration in milliseconds for recurring execution."
          }
        }
      },
      "QueryDSL": {
        "id": "type:QueryDSL",
        "definition": "type QueryDSL struct {\n    Filters      *QueryFilter\n    Sort         []SortConfiguration\n    Pagination   *PaginationOptions\n    Projection   *ProjectionConfiguration\n    Joins        []JoinConfiguration\n    Aggregations []AggregationConfiguration\n    Hints        []QueryHint\n}",
        "purpose": "The core declarative language for defining data queries, including filters, sorting, pagination, projections, joins, aggregations, and hints.",
        "related": {
          "methods": [
            "method:query.NewQueryBuilder",
            "method:query.QueryBuilder.Build",
            "method:core.PersistenceCollectionInterface.Read",
            "method:sqlite.SqliteQuery.GenerateSelectSQL"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Filters": "*QueryFilter - Specifies conditions for filtering documents.",
            "Sort": "[]SortConfiguration - Defines the order of results.",
            "Pagination": "*PaginationOptions - Controls limits and offsets for results.",
            "Projection": "*ProjectionConfiguration - Defines which fields to include/exclude and computed fields.",
            "Joins": "[]JoinConfiguration - Specifies how to join with other collections.",
            "Aggregations": "[]AggregationConfiguration - Defines aggregation functions to apply.",
            "Hints": "[]QueryHint - Provides database-specific optimization hints."
          }
        }
      },
      "QueryFilter": {
        "id": "type:QueryFilter",
        "definition": "type QueryFilter struct {\n    Condition *FilterCondition\n    Group     *FilterGroup\n}",
        "purpose": "Represents a single filter condition or a logical group of conditions, forming the WHERE clause of a query.",
        "related": {
          "methods": [
            "method:query.QueryBuilder.Where",
            "method:query.QueryBuilder.WhereGroup",
            "method:sqlite.SqliteQuery.buildWhereClause",
            "method:core.PersistenceCollectionInterface.Update",
            "method:core.PersistenceCollectionInterface.Delete"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Condition": "*FilterCondition - A single comparison condition.",
            "Group": "*FilterGroup - A logical grouping of multiple conditions."
          }
        }
      },
      "FilterCondition": {
        "id": "type:FilterCondition",
        "definition": "type FilterCondition struct {\n    Field    string\n    Operator ComparisonOperator\n    Value    FilterValue\n}",
        "purpose": "Defines a single comparison operation for filtering documents.",
        "related": {
          "methods": [
            "method:query.FilterConditionBuilder.Eq",
            "method:query.FilterConditionBuilder.Lt",
            "method:sqlite.SqliteQuery.buildCondition"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Field": "string - The name of the field to apply the filter to.",
            "Operator": "ComparisonOperator - The type of comparison (e.g., `eq`, `gt`, `contains`).",
            "Value": "FilterValue - The value to compare against."
          }
        }
      },
      "FilterGroup": {
        "id": "type:FilterGroup",
        "definition": "type FilterGroup struct {\n    Operator   LogicalOperator\n    Conditions []QueryFilter\n}",
        "purpose": "Combines multiple filter conditions using a logical operator (AND, OR, etc.).",
        "related": {
          "methods": [
            "method:query.QueryBuilder.WhereGroup",
            "method:sqlite.SqliteQuery.buildWhereClause"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Operator": "LogicalOperator - The logical operator (`and`, `or`, etc.) applied to the conditions.",
            "Conditions": "[]QueryFilter - A slice of nested `QueryFilter`s (conditions or other groups)."
          }
        }
      },
      "SortConfiguration": {
        "id": "type:SortConfiguration",
        "definition": "type SortConfiguration struct {\n    Field     string\n    Direction SortDirection\n}",
        "purpose": "Specifies how documents should be sorted based on a particular field and direction.",
        "related": {
          "methods": [
            "method:query.QueryBuilder.OrderByAsc",
            "method:query.QueryBuilder.OrderByDesc",
            "method:sqlite.SqliteQuery.GenerateSelectSQL"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Field": "string - The field to sort by.",
            "Direction": "SortDirection - The sorting order (`asc` or `desc`)."
          }
        }
      },
      "PaginationOptions": {
        "id": "type:PaginationOptions",
        "definition": "type PaginationOptions struct {\n    Type   string\n    Limit  int\n    Offset *int\n    Cursor *string\n}",
        "purpose": "Defines pagination settings for a query, including limit, offset, or cursor-based pagination.",
        "related": {
          "methods": [
            "method:query.QueryBuilder.Limit",
            "method:query.QueryBuilder.Offset",
            "method:query.QueryBuilder.Cursor",
            "method:sqlite.SqliteQuery.GenerateSelectSQL"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "string - The type of pagination (`\"offset\"` or `\"cursor\"`).",
            "Limit": "int - The maximum number of documents to return.",
            "Offset": "*int - For offset-based pagination, the number of documents to skip.",
            "Cursor": "*string - For cursor-based pagination, the opaque cursor string."
          }
        }
      },
      "ProjectionConfiguration": {
        "id": "type:ProjectionConfiguration",
        "definition": "type ProjectionConfiguration struct {\n    Include  []ProjectionField\n    Exclude  []ProjectionField\n    Computed []ProjectionComputedItem\n}",
        "purpose": "Specifies which fields to include or exclude from the query result, and defines any computed fields.",
        "related": {
          "methods": [
            "method:query.QueryBuilder.Select",
            "method:query.ProjectionBuilder.Include",
            "method:query.ProjectionBuilder.Exclude",
            "method:query.ProjectionBuilder.AddComputed",
            "method:sqlite.SqliteQuery.GenerateSelectSQL",
            "method:query.DataProcessor.DetermineFieldsToSelect",
            "method:query.DataProcessor.applyFinalProjection"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Include": "[]ProjectionField - A list of fields to include in the result. Mutually exclusive with `Exclude`.",
            "Exclude": "[]ProjectionField - A list of fields to exclude from the result. Mutually exclusive with `Include`.",
            "Computed": "[]ProjectionComputedItem - A list of dynamically generated (computed) fields."
          }
        }
      },
      "ProjectionField": {
        "id": "type:ProjectionField",
        "definition": "type ProjectionField struct {\n    Name   string\n    Nested *ProjectionConfiguration\n}",
        "purpose": "Defines a single field for inclusion or exclusion in a projection, with optional nested projection for complex types.",
        "related": {
          "methods": [
            "method:query.ProjectionBuilder.Include",
            "method:query.ProjectionBuilder.Exclude"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Name": "string - The name of the field.",
            "Nested": "*ProjectionConfiguration - (Optional) For nested objects, defines a sub-projection."
          }
        }
      },
      "ComputedFieldExpression": {
        "id": "type:ComputedFieldExpression",
        "definition": "type ComputedFieldExpression struct {\n    Type       string\n    Expression *FunctionCall\n    Alias      string\n}",
        "purpose": "Describes how a new field's value is computed using a function call, often a Go-based `ComputeFunction`.",
        "related": {
          "methods": [
            "method:query.ProjectionBuilder.AddComputed",
            "method:query.DataProcessor.applyGoComputeFunctions"
          ],
          "patterns": [
            "pattern:Using Go Functions"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "string - Always `\"computed\"` for this type of expression.",
            "Expression": "*FunctionCall - Details about the function to call (name, arguments).",
            "Alias": "string - The name of the new computed field in the query result."
          }
        }
      },
      "CaseCondition": {
        "id": "type:CaseCondition",
        "definition": "type CaseCondition struct {\n    When QueryFilter\n    Then FilterValue\n}",
        "purpose": "Represents a single `WHEN ... THEN ...` clause within a `CaseExpression`.",
        "related": {
          "methods": [
            "method:query.ProjectionBuilder.AddCase"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "When": "QueryFilter - The condition that must be true for this case to be selected.",
            "Then": "FilterValue - The value to return if the `When` condition is true."
          }
        }
      },
      "CaseExpression": {
        "id": "type:CaseExpression",
        "definition": "type CaseExpression struct {\n    Type  string\n    Cases []CaseCondition\n    Else  FilterValue\n    Alias string\n}",
        "purpose": "Defines a conditional expression, similar to SQL's `CASE` statement, where a value is chosen based on a series of conditions.",
        "related": {
          "methods": [
            "method:query.ProjectionBuilder.AddCase"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "string - Always `\"case\"` for this type of expression.",
            "Cases": "[]CaseCondition - An ordered list of `WHEN ... THEN ...` pairs.",
            "Else": "FilterValue - The default value to return if none of the `Cases` conditions are met.",
            "Alias": "string - The name of the new field in the query result."
          }
        }
      },
      "ProjectionComputedItem": {
        "id": "type:ProjectionComputedItem",
        "definition": "type ProjectionComputedItem struct {\n    ComputedFieldExpression *ComputedFieldExpression\n    CaseExpression          *CaseExpression\n}",
        "purpose": "A union type representing either a `ComputedFieldExpression` or a `CaseExpression` within a `ProjectionConfiguration`.",
        "related": {
          "methods": [
            "method:query.ProjectionBuilder.AddComputed",
            "method:query.ProjectionBuilder.AddCase"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "ComputedFieldExpression": "*ComputedFieldExpression - Defines a computed field based on a function call.",
            "CaseExpression": "*CaseExpression - Defines a conditional `CASE` expression."
          }
        }
      },
      "JoinConfiguration": {
        "id": "type:JoinConfiguration",
        "definition": "type JoinConfiguration struct {\n    Type        JoinType\n    TargetTable string\n    On          QueryFilter\n    Alias       string\n    Projection  *ProjectionConfiguration\n}",
        "purpose": "Defines a join operation between the main collection and another target collection.",
        "related": {
          "methods": [
            "method:query.QueryBuilder.InnerJoin",
            "method:query.QueryBuilder.LeftJoin"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "JoinType - The type of join (`inner`, `left`, `right`, `full`).",
            "TargetTable": "string - The name of the table to join with.",
            "On": "QueryFilter - The join condition (`ON` clause).",
            "Alias": "string - An alias for the joined table.",
            "Projection": "*ProjectionConfiguration - (Optional) Defines projection for fields from the joined table."
          }
        }
      },
      "AggregationConfiguration": {
        "id": "type:AggregationConfiguration",
        "definition": "type AggregationConfiguration struct {\n    Type  AggregationType\n    Field string\n    Alias string\n}",
        "purpose": "Defines an aggregation function (e.g., COUNT, SUM) to be applied to a field in a query.",
        "related": {
          "methods": [
            "method:query.QueryBuilder.Count",
            "method:query.QueryBuilder.Sum"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "AggregationType - The type of aggregation (`count`, `sum`, `avg`, `min`, `max`).",
            "Field": "string - The field to aggregate (empty for `count(*)`).",
            "Alias": "string - The alias for the result of the aggregation."
          }
        }
      },
      "QueryHint": {
        "id": "type:QueryHint",
        "definition": "type QueryHint struct {\n    Type    string\n    Index   string\n    Seconds int\n}",
        "purpose": "Provides database-specific hints to optimize query execution (e.g., specifying an index to use).",
        "related": {
          "methods": [
            "method:query.QueryBuilder.UseIndex",
            "method:query.QueryBuilder.MaxExecutionTime"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Type": "string - The type of hint (`\"index\"`, `\"force_index\"`, `\"max_execution_time\"`, etc.).",
            "Index": "string - For index-related hints, the name of the index.",
            "Seconds": "int - For `max_execution_time` hint, the maximum execution duration in seconds."
          }
        }
      },
      "QueryResult": {
        "id": "type:QueryResult",
        "definition": "type QueryResult struct {\n    Data       any\n    Count      int\n    Pagination *struct { Total *int; NextCursor *string }\n    Aggregations map[string]any\n}",
        "purpose": "The standardized result structure returned by `Read` operations, containing the fetched data, count, and optional pagination/aggregation details.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.Read",
            "method:persistence.Collection.Read",
            "method:persistence.Executor.Query",
            "method:persistence.Executor.Insert"
          ],
          "patterns": [
            "pattern:Querying Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Data": "any - The actual results, either a single `query.Document` (map[string]any) for single fetches or `[]query.Document` for multiple.",
            "Count": "int - The number of documents returned in `Data`.",
            "Pagination": "*struct{...} - Optional pagination metadata, including total count and next cursor.",
            "Aggregations": "map[string]any - Optional map of aggregation results."
          }
        }
      },
      "Document": {
        "id": "type:Document",
        "definition": "type Document map[string]any",
        "purpose": "Represents a single record or row of data retrieved from or inserted into the database, used as a generic map.",
        "related": {
          "methods": [
            "method:sqlite.readRows",
            "method:sqlite.SQLiteInteractor.SelectDocuments",
            "method:query.DataProcessor.ProcessRows",
            "method:query.ComputeFunction",
            "method:query.PredicateFunction"
          ],
          "patterns": [
            "pattern:Insert Single Document",
            "pattern:Read All Documents"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {}
        }
      },
      "ComputeFunction": {
        "id": "type:ComputeFunction",
        "definition": "type ComputeFunction func(row Document, args FilterValue) (any, error)",
        "purpose": "A Go function type used for defining custom computed fields. It takes a document and optional arguments, returning the computed value.",
        "related": {
          "methods": [
            "method:persistence.Executor.RegisterComputeFunction",
            "method:query.DataProcessor.RegisterComputeFunction",
            "method:query.DataProcessor.applyGoComputeFunctions"
          ],
          "patterns": [
            "pattern:Using Go Functions"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "row": "Document - The current document being processed.",
            "args": "FilterValue - Optional arguments passed to the compute function from the query DSL."
          }
        }
      },
      "PredicateFunction": {
        "id": "type:PredicateFunction",
        "definition": "type PredicateFunction func(doc Document, field string, args FilterValue) (bool, error)",
        "purpose": "A Go function type used for defining custom in-memory filter predicates. It takes a document, a field, and arguments, returning `true` if the document matches the filter.",
        "related": {
          "methods": [
            "method:persistence.Executor.RegisterFilterFunction",
            "method:query.DataProcessor.RegisterFilterFunction",
            "method:query.DataProcessor.applyGoFilters",
            "method:query.DataProcessor.Match"
          ],
          "patterns": [
            "pattern:Using Go Functions"
          ]
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "doc": "Document - The current document being evaluated.",
            "field": "string - The field name the predicate is applied to.",
            "args": "FilterValue - Optional arguments passed to the predicate function from the query DSL."
          }
        }
      },
      "InteractorOptions": {
        "id": "type:InteractorOptions",
        "definition": "type InteractorOptions struct {\n    IfNotExists   bool\n    DropIfExists  bool\n    CreateIndexes bool\n    TablePrefix string\n    SchemaName string\n}",
        "purpose": "Configuration options for database interactors, influencing DDL operations like table creation and naming conventions.",
        "related": {
          "methods": [
            "method:sqlite.NewSQLiteInteractor",
            "method:sqlite.DefaultInteractorOptions"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "IfNotExists": "bool - If true, `CREATE TABLE` statements will include `IF NOT EXISTS`.",
            "DropIfExists": "bool - If true, `DROP TABLE IF EXISTS` will be executed before creating a new table.",
            "CreateIndexes": "bool - If true, indexes defined in the schema will be created automatically.",
            "TablePrefix": "string - A prefix prepended to all table names.",
            "SchemaName": "string - (For databases supporting schemas like PostgreSQL) The database schema name."
          }
        }
      },
      "SchemaRecord": {
        "id": "type:SchemaRecord",
        "definition": "type SchemaRecord struct {\n    Name        string\n    Description string\n    Version     string\n    Schema      json.RawMessage\n}",
        "purpose": "An internal struct representing how schema definitions are stored within the special `_schemas` collection.",
        "related": {
          "methods": [
            "method:persistence.mapToSchemaRecord",
            "method:persistence.schemaRecordToMap",
            "method:persistence.Persistence.Schema"
          ],
          "patterns": []
        },
        "interfaceContract": {
          "requiredMethods": [],
          "optionalMethods": [],
          "parameterObjectStructures": {
            "Name": "string - The name of the collection the schema defines.",
            "Description": "string - A description of the schema.",
            "Version": "string - The version of the schema.",
            "Schema": "json.RawMessage - The full schema definition as raw JSON bytes."
          }
        }
      }
    },
    "methods": {
      "sqlite.NewSQLiteInteractor": {
        "id": "method:sqlite.NewSQLiteInteractor",
        "useCase": "To create a new instance of the SQLite database interactor, which handles low-level database operations and DDL for SQLite. Used to provide a `persistence.DatabaseInteractor` to `persistence.NewPersistence`.",
        "signature": "func NewSQLiteInteractor(db *sql.DB, logger *zap.Logger, options *persistence.InteractorOptions, tx *sql.Tx) persistence.DatabaseInteractor",
        "parameters": "`db`: `*sql.DB` - The underlying database connection pool. `logger`: `*zap.Logger` - An optional Zap logger for interactor-specific logging. `options`: `*persistence.InteractorOptions` - Optional configuration for the interactor (e.g., table prefixes, DDL behavior). `tx`: `*sql.Tx` - An optional active SQL transaction. If provided, the interactor operates in transactional mode; otherwise, it's non-transactional.",
        "prerequisites": "An initialized `*sql.DB` connection pool. `go.uber.org/zap` for logging (can be `zap.NewNop()` for no-op logger).",
        "sideEffects": "Initializes internal state for database operations. If `tx` is not nil, subsequent operations will be part of that transaction.",
        "returnValue": "`persistence.DatabaseInteractor` - A new interactor instance configured for SQLite operations.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:persistence.DatabaseInteractor"],
          "patterns": ["pattern:Database Initialization"]
        }
      },
      "sqlite.SQLiteInteractor.SelectDocuments": {
        "id": "method:sqlite.SQLiteInteractor.SelectDocuments",
        "useCase": "To execute a SELECT query against the SQLite database and retrieve documents matching a `QueryDSL`. This is the low-level read operation.",
        "signature": "func (e *SQLiteInteractor) SelectDocuments(ctx context.Context, schema *core.SchemaDefinition, dsl *query.QueryDSL) ([]query.Document, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts. `schema`: `*core.SchemaDefinition` - The schema definition of the collection being queried. `dsl`: `*query.QueryDSL` - The declarative query object.",
        "prerequisites": "The collection defined by `schema` must exist in the database.",
        "sideEffects": "Reads data from the database.",
        "returnValue": "`[]query.Document` - A slice of `query.Document` (map[string]any) representing the fetched rows. `error` - An error if the operation fails.",
        "exceptions": [
          "`fmt.Errorf` (wrapped `fmt.Errorf`): \"could not get a query generator instance\"",
          "`fmt.Errorf`: \"failed to generate SQL query\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to execute SELECT query\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to get columns\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to scan row\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"error after scanning rows\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL", "type:Document"],
          "patterns": ["pattern:Querying Documents"]
        }
      },
      "sqlite.SQLiteInteractor.UpdateDocuments": {
        "id": "method:sqlite.SQLiteInteractor.UpdateDocuments",
        "useCase": "To execute an UPDATE query against the SQLite database, modifying documents based on a filter.",
        "signature": "func (e *SQLiteInteractor) UpdateDocuments(ctx context.Context, schema *core.SchemaDefinition, updates map[string]any, filters *query.QueryFilter) (int64, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts. `schema`: `*core.SchemaDefinition` - The schema definition of the collection being updated. `updates`: `map[string]any` - A map of field names to their new values. `filters`: `*query.QueryFilter` - The filter defining which documents to update.",
        "prerequisites": "The collection defined by `schema` must exist in the database.",
        "sideEffects": "Modifies data in the database.",
        "returnValue": "`int64` - The number of rows affected by the update. `error` - An error if the operation fails.",
        "exceptions": [
          "`fmt.Errorf` (wrapped `fmt.Errorf`): \"could not get a query generator instance\"",
          "`fmt.Errorf`: \"failed to generate SQL UPDATE query\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to execute UPDATE query\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter"],
          "patterns": ["pattern:Update Documents"]
        }
      },
      "sqlite.SQLiteInteractor.InsertDocuments": {
        "id": "method:sqlite.SQLiteInteractor.InsertDocuments",
        "useCase": "To execute an INSERT query against the SQLite database, inserting one or more documents and atomically returning the inserted records.",
        "signature": "func (e *SQLiteInteractor) InsertDocuments(ctx context.Context, schema *core.SchemaDefinition, records []map[string]any) ([]query.Document, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts. `schema`: `*core.SchemaDefinition` - The schema definition of the collection being inserted into. `records`: `[]map[string]any` - A slice of maps, where each map represents a document to insert.",
        "prerequisites": "The collection defined by `schema` must exist in the database. Requires SQLite 3.35.0+ for `RETURNING *` clause.",
        "sideEffects": "Inserts data into the database.",
        "returnValue": "`[]query.Document` - A slice of `query.Document` representing the newly inserted records, including any auto-generated IDs or default values. `error` - An error if the operation fails.",
        "exceptions": [
          "`fmt.Errorf` (wrapped `fmt.Errorf`): \"could not get a query generator instance\"",
          "`fmt.Errorf`: \"failed to generate INSERT SQL\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to execute INSERT ... RETURNING query\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:Document"],
          "patterns": ["pattern:Insert Single Document"]
        }
      },
      "sqlite.SQLiteInteractor.DeleteDocuments": {
        "id": "method:sqlite.SQLiteInteractor.DeleteDocuments",
        "useCase": "To execute a DELETE query against the SQLite database, removing documents based on a filter.",
        "signature": "func (e *SQLiteInteractor) DeleteDocuments(ctx context.Context, schema *core.SchemaDefinition, filters *query.QueryFilter, unsafeDelete bool) (int64, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts. `schema`: `*core.SchemaDefinition` - The schema definition of the collection. `filters`: `*query.QueryFilter` - The filter defining which documents to delete. If nil, `unsafeDelete` must be true. `unsafeDelete`: `bool` - If true, allows deleting all records if `filters` is nil.",
        "prerequisites": "The collection defined by `schema` must exist in the database.",
        "sideEffects": "Deletes data from the database.",
        "returnValue": "`int64` - The number of rows affected by the delete. `error` - An error if the operation fails.",
        "exceptions": [
          "`fmt.Errorf`: \"DELETE without WHERE clause is not allowed for safety. Set unsafeDelete=true to override\"",
          "`fmt.Errorf` (wrapped `fmt.Errorf`): \"could not get a query generator instance\"",
          "`fmt.Errorf`: \"failed to generate DELETE SQL\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to execute DELETE query\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter"],
          "patterns": ["pattern:Delete Documents"]
        }
      },
      "sqlite.SQLiteInteractor.StartTransaction": {
        "id": "method:sqlite.SQLiteInteractor.StartTransaction",
        "useCase": "To initiate a new database transaction. This method returns a *new* `DatabaseInteractor` instance that operates within the scope of the initiated transaction. The original interactor instance remains unchanged and non-transactional.",
        "signature": "func (e *SQLiteInteractor) StartTransaction(ctx context.Context) (persistence.DatabaseInteractor, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts for the transaction initiation.",
        "prerequisites": "The `SQLiteInteractor` instance must not already be in a transactional context (i.e., its internal `tx` field must be `nil`).",
        "sideEffects": "Begins a new SQL transaction on the underlying database connection.",
        "returnValue": "`persistence.DatabaseInteractor` - A new interactor instance bound to the newly started transaction. All subsequent database operations on this *new* instance will be part of this transaction. `error` - An error if the transaction cannot be started (e.g., already in transaction, database error).",
        "exceptions": [
          "`fmt.Errorf`: \"Cannot start a new transaction from an existing transactional interactor\"",
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to begin transaction\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:persistence.DatabaseInteractor"],
          "patterns": ["pattern:Transaction Management"]
        }
      },
      "sqlite.SQLiteInteractor.Commit": {
        "id": "method:sqlite.SQLiteInteractor.Commit",
        "useCase": "To commit the current database transaction. All changes made within the transaction's scope are permanently saved to the database.",
        "signature": "func (e *SQLiteInteractor) Commit(ctx context.Context) error",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts for the commit operation.",
        "prerequisites": "This method must be called on an `SQLiteInteractor` instance that was created with an active transaction (i.e., its internal `tx` field is not `nil`), typically an instance returned by `StartTransaction()`.",
        "sideEffects": "Commits the active SQL transaction. If successful, changes become permanent.",
        "returnValue": "`error` - An error if the commit operation fails (e.g., network issues, constraint violations, or not in a transactional context).",
        "exceptions": [
          "`fmt.Errorf`: \"Commit not applicable: not in a transactional context\"",
          "Error from `sql.Tx.Commit()`"
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": ["pattern:Transaction Management"]
        }
      },
      "sqlite.SQLiteInteractor.Rollback": {
        "id": "method:sqlite.SQLiteInteractor.Rollback",
        "useCase": "To roll back (undo) the current database transaction. All changes made within the transaction's scope are discarded.",
        "signature": "func (e *SQLiteInteractor) Rollback(ctx context.Context) error",
        "parameters": "`ctx`: `context.Context` - Context for cancellation and timeouts for the rollback operation.",
        "prerequisites": "This method must be called on an `SQLiteInteractor` instance that was created with an active transaction (i.e., its internal `tx` field is not `nil`), typically an instance returned by `StartTransaction()`.",
        "sideEffects": "Rolls back the active SQL transaction. If successful, any changes made within the transaction are undone.",
        "returnValue": "`error` - An error if the rollback operation fails (e.g., network issues, or not in a transactional context).",
        "exceptions": [
          "`fmt.Errorf`: \"Rollback not applicable: not in a transactional context\"",
          "Error from `sql.Tx.Rollback()`"
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": ["pattern:Transaction Management"]
        }
      },
      "sqlite.SQLiteInteractor.CreateCollection": {
        "id": "method:sqlite.SQLiteInteractor.CreateCollection",
        "useCase": "To generate and execute DDL (Data Definition Language) statements to create a new table and its associated indexes in the SQLite database, based on a provided schema definition.",
        "signature": "func (s *SQLiteInteractor) CreateCollection(schema core.SchemaDefinition) error",
        "parameters": "`schema`: `core.SchemaDefinition` - The schema defining the table and its fields and indexes.",
        "prerequisites": "The database connection (`s.db`) must be open. Options (`s.options`) can influence behavior (e.g., `DropIfExists`, `IfNotExists`, `CreateIndexes`).",
        "sideEffects": "Creates a new table and potentially indexes in the database. May drop an existing table if `DropIfExists` option is true.",
        "returnValue": "`error` - An error if DDL generation or execution fails.",
        "exceptions": [
          "`fmt.Errorf`: \"failed to drop table %s\"",
          "`fmt.Errorf`: \"failed to generate SQL for table %s\"",
          "`fmt.Errorf`: \"failed to execute SQL statement '%s'\"",
          "`fmt.Errorf`: \"failed to generate SQL for index %s\"",
          "`fmt.Errorf`: \"failed to create index %s\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:SchemaDefinition"],
          "patterns": ["pattern:Collection Creation"]
        }
      },
      "sqlite.SQLiteInteractor.GetColumnType": {
        "id": "method:sqlite.SQLiteInteractor.GetColumnType",
        "useCase": "To map a generic `core.FieldType` (e.g., \"string\", \"integer\") to an appropriate SQLite-specific column type (e.g., `TEXT`, `INTEGER`).",
        "signature": "func (s *SQLiteInteractor) GetColumnType(fieldType core.FieldType, field *core.FieldDefinition) string",
        "parameters": "`fieldType`: `core.FieldType` - The generic field type from the schema. `field`: `*core.FieldDefinition` - The field definition (currently not directly used by this function but available for future complex mappings).",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`string` - The SQLite column type string (e.g., `\"TEXT\"`, `\"INTEGER\"`, `\"REAL\"`, `\"BLOB\"`).",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:FieldType", "type:FieldDefinition"],
          "patterns": []
        }
      },
      "sqlite.SQLiteInteractor.CreateIndex": {
        "id": "method:sqlite.SQLiteInteractor.CreateIndex",
        "useCase": "To generate and execute DDL to create a specific index on an existing table.",
        "signature": "func (s *SQLiteInteractor) CreateIndex(collection string, index core.IndexDefinition) error",
        "parameters": "`collection`: `string` - The base name of the collection (table) on which to create the index. `index`: `core.IndexDefinition` - The definition of the index to create.",
        "prerequisites": "The target table must already exist in the database.",
        "sideEffects": "Creates an index in the database.",
        "returnValue": "`error` - An error if DDL generation or execution fails.",
        "exceptions": [
          "`fmt.Errorf`: \"failed to generate SQL for index %s\"",
          "`fmt.Errorf`: \"failed to execute create index statement\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:IndexDefinition"],
          "patterns": []
        }
      },
      "sqlite.SQLiteInteractor.DropCollection": {
        "id": "method:sqlite.SQLiteInteractor.DropCollection",
        "useCase": "To drop (delete) a table from the SQLite database if it exists, along with any associated indexes.",
        "signature": "func (s *SQLiteInteractor) DropCollection(collection string) error",
        "parameters": "`collection`: `string` - The base name of the collection (table) to drop.",
        "prerequisites": "None.",
        "sideEffects": "Deletes the specified table from the database.",
        "returnValue": "`error` - An error if the drop operation fails.",
        "exceptions": [
          "`fmt.Errorf` (wrapped `error` from `sql` driver): \"failed to drop table %s\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "sqlite.SQLiteInteractor.CollectionExists": {
        "id": "method:sqlite.SQLiteInteractor.CollectionExists",
        "useCase": "To check if a table with a given base name (and applied prefix) currently exists in the SQLite database.",
        "signature": "func (s *SQLiteInteractor) CollectionExists(collection string) (bool, error)",
        "parameters": "`collection`: `string` - The base name of the collection (table) to check.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`bool` - True if the table exists, false otherwise. `error` - An error if the database query fails (e.g., connection issues).",
        "exceptions": [
          "Error from `sql.Row.Scan()` if not `sql.ErrNoRows`"
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "sqlite.NewSqliteQueryGeneratorFactory": {
        "id": "method:sqlite.NewSqliteQueryGeneratorFactory",
        "useCase": "To create a new factory instance responsible for producing SQLite-specific query generators (`sqlite.SqliteQuery`).",
        "signature": "func NewSqliteQueryGeneratorFactory() *SqliteQueryGeneratorFactory",
        "parameters": "None",
        "prerequisites": "None",
        "sideEffects": "None",
        "returnValue": "`*SqliteQueryGeneratorFactory` - A new factory instance.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:query.QueryGeneratorFactory"],
          "patterns": []
        }
      },
      "sqlite.SqliteQueryGeneratorFactory.CreateGenerator": {
        "id": "method:sqlite.SqliteQueryGeneratorFactory.CreateGenerator",
        "useCase": "To create a new SQLite-specific query generator (`sqlite.SqliteQuery`) for a given schema. This generator is responsible for translating Anansi's `QueryDSL` into SQLite SQL.",
        "signature": "func (f *SqliteQueryGeneratorFactory) CreateGenerator(schema *core.SchemaDefinition) (querydsl.QueryGenerator, error)",
        "parameters": "`schema`: `*core.SchemaDefinition` - The schema definition that the query generator will operate against.",
        "prerequisites": "None",
        "sideEffects": "None",
        "returnValue": "`querydsl.QueryGenerator` - A new `SqliteQuery` instance. `error` - An error if the schema is invalid (e.g., nil or missing name).",
        "exceptions": [
          "`fmt.Errorf`: \"SchemaDefinition cannot be nil\"",
          "`fmt.Errorf`: \"schema must define a table name\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:query.QueryGenerator", "type:SchemaDefinition"],
          "patterns": []
        }
      },
      "sqlite.SqliteQuery.GenerateSelectSQL": {
        "id": "method:sqlite.SqliteQuery.GenerateSelectSQL",
        "useCase": "To translate a `query.QueryDSL` object into a complete SQLite `SELECT` SQL query string and its corresponding parameters.",
        "signature": "func (s *SqliteQuery) GenerateSelectSQL(dsl *query.QueryDSL) (string, []any, error)",
        "parameters": "`dsl`: `*query.QueryDSL` - The declarative query object.",
        "prerequisites": "The `SqliteQuery` must be initialized with a valid `core.SchemaDefinition`.",
        "sideEffects": "None.",
        "returnValue": "`string` - The generated SQL `SELECT` query. `[]any` - A slice of parameters to be bound to the SQL query. `error` - An error if SQL generation fails (e.g., invalid field path, unsupported operator).",
        "exceptions": [
          "`fmt.Errorf`: \"QueryDSL cannot be nil\"",
          "`fmt.Errorf`: \"projection error: %w\" (wrapped field not found or nested querying error)",
          "`fmt.Errorf`: \"error building WHERE clause: %w\" (wrapped filter errors)",
          "`fmt.Errorf`: \"sort error: %w\" (wrapped field not found error)",
          "`fmt.Errorf`: \"field '%s' not found in schema\"",
          "`fmt.Errorf`: \"field '%s' of type %s does not support nested querying\"",
          "`fmt.Errorf`: \"logical operator missing in filter group\"",
          "`fmt.Errorf`: \"invalid filter structure: neither Condition nor Group is set\"",
          "`fmt.Errorf`: \"failed to prepare value for condition field '%s'\"",
          "`fmt.Errorf`: \"expected boolean for FieldTypeBoolean, got %T for field '%s'\"",
          "`fmt.Errorf`: \"failed to serialize field '%s' to JSON\"",
          "`fmt.Errorf`: \"unsupported comparison operator for direct SQL: %s\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL", "type:QueryGenerator"],
          "patterns": ["pattern:Querying Documents"]
        }
      },
      "sqlite.SqliteQuery.GenerateUpdateSQL": {
        "id": "method:sqlite.SqliteQuery.GenerateUpdateSQL",
        "useCase": "To translate update data and filters into a complete SQLite `UPDATE` SQL query string and its corresponding parameters.",
        "signature": "func (s *SqliteQuery) GenerateUpdateSQL(updates map[string]any, filters *query.QueryFilter) (string, []any, error)",
        "parameters": "`updates`: `map[string]any` - A map of field names to their new values. `filters`: `*query.QueryFilter` - The filter defining which documents to update.",
        "prerequisites": "The `SqliteQuery` must be initialized with a valid `core.SchemaDefinition`.",
        "sideEffects": "None.",
        "returnValue": "`string` - The generated SQL `UPDATE` query. `[]any` - A slice of parameters to be bound to the SQL query. `error` - An error if SQL generation fails (e.g., no updates provided, invalid field path, unsupported operator).",
        "exceptions": [
          "`fmt.Errorf`: \"no fields provided for update\"",
          "`fmt.Errorf`: \"update set clause error for field '%s': %w\"",
          "`fmt.Errorf`: \"error preparing value for field '%s': %w\"",
          "`fmt.Errorf`: \"error building WHERE clause for update: %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter", "type:QueryGenerator"],
          "patterns": ["pattern:Update Documents"]
        }
      },
      "sqlite.SqliteQuery.GenerateInsertSQL": {
        "id": "method:sqlite.SqliteQuery.GenerateInsertSQL",
        "useCase": "To translate records into a complete SQLite `INSERT` SQL query string with a `RETURNING *` clause, and its corresponding parameters. Supports batch inserts.",
        "signature": "func (s *SqliteQuery) GenerateInsertSQL(records []map[string]any) (string, []any, error)",
        "parameters": "`records`: `[]map[string]any` - A slice of maps, where each map represents a document to insert.",
        "prerequisites": "The `SqliteQuery` must be initialized with a valid `core.SchemaDefinition`. Requires SQLite 3.35.0+ for `RETURNING *` clause.",
        "sideEffects": "None.",
        "returnValue": "`string` - The generated SQL `INSERT ... RETURNING *` query. `[]any` - A slice of parameters to be bound to the SQL query. `error` - An error if SQL generation fails (e.g., no records, invalid field not in schema).",
        "exceptions": [
          "`fmt.Errorf`: \"no records provided for insert\"",
          "`fmt.Errorf`: \"field '%s' not found in schema\"",
          "`fmt.Errorf`: \"no valid fields found in records\"",
          "`fmt.Errorf`: \"error preparing value for field '%s': %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryGenerator"],
          "patterns": ["pattern:Insert Single Document"]
        }
      },
      "sqlite.SqliteQuery.GenerateDeleteSQL": {
        "id": "method:sqlite.SqliteQuery.GenerateDeleteSQL",
        "useCase": "To translate filters into a complete SQLite `DELETE` SQL query string and its corresponding parameters.",
        "signature": "func (s *SqliteQuery) GenerateDeleteSQL(filters *query.QueryFilter, unsafeDelete bool) (string, []any, error)",
        "parameters": "`filters`: `*query.QueryFilter` - The filter defining which documents to delete. If nil, `unsafeDelete` must be true. `unsafeDelete`: `bool` - If true, allows deleting all records if `filters` is nil.",
        "prerequisites": "The `SqliteQuery` must be initialized with a valid `core.SchemaDefinition`.",
        "sideEffects": "None.",
        "returnValue": "`string` - The generated SQL `DELETE` query. `[]any` - A slice of parameters to be bound to the SQL query. `error` - An error if SQL generation fails (e.g., no filter and unsafeDelete is false).",
        "exceptions": [
          "`fmt.Errorf`: \"DELETE without WHERE clause is not allowed for safety. Set unsafeDelete=true to override\"",
          "`fmt.Errorf`: \"error building WHERE clause for delete: %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter", "type:QueryGenerator"],
          "patterns": ["pattern:Delete Documents"]
        }
      },
      "persistence.NewPersistence": {
        "id": "method:persistence.NewPersistence",
        "useCase": "To create the top-level Anansi persistence service. This service manages collections (tables), schemas, and provides global transaction and event capabilities.",
        "signature": "func NewPersistence(interactor persistence.DatabaseInteractor, fmap core.FunctionMap) (*Persistence, error)",
        "parameters": "`interactor`: `persistence.DatabaseInteractor` - The database-specific interactor (e.g., `sqlite.NewSQLiteInteractor`) that handles low-level DB operations. `fmap`: `core.FunctionMap` - A map of custom Go functions for computed fields and predicates, available globally.",
        "prerequisites": "An initialized `persistence.DatabaseInteractor` instance.",
        "sideEffects": "Initializes the internal `_schemas` collection in the database if it doesn't exist. Registers global Go functions from `fmap`.",
        "returnValue": "`*Persistence` - A new `Persistence` service instance. `error` - An error if schema unmarshaling fails, if the `_schemas` collection cannot be created, or if the internal `_schemas` collection cannot be initialized.",
        "exceptions": [
          "`fmt.Errorf`: \"Error unmarshaling JSON: %v\"",
          "`fmt.Errorf`: \"Error looking up schema collection: %v\"",
          "`fmt.Errorf`: \"Failed to create table for collections %s: %w\"",
          "`fmt.Errorf`: \"Failed to initialize schemas collection collections %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:persistence.DatabaseInteractor", "type:core.FunctionMap"],
          "patterns": ["pattern:Database Initialization"]
        }
      },
      "persistence.Persistence.Collection": {
        "id": "method:persistence.Persistence.Collection",
        "useCase": "To retrieve a `PersistenceCollectionInterface` instance for a specific collection (table). This instance allows performing CRUD and collection-scoped operations.",
        "signature": "func (pi *Persistence) Collection(name string) (core.PersistenceCollectionInterface, error)",
        "parameters": "`name`: `string` - The name of the collection to retrieve.",
        "prerequisites": "The collection must have been previously created and its schema stored in the `_schemas` collection.",
        "sideEffects": "None.",
        "returnValue": "`core.PersistenceCollectionInterface` - An interface to interact with the specified collection. `error` - An error if the collection's schema cannot be found or initialized.",
        "exceptions": [
          "`fmt.Errorf`: \"Collection %s does not exist: %v\"",
          "`fmt.Errorf`: \"Error accessing database: %v, %t\"",
          "`fmt.Errorf`: \"Error reading schema collection: %v\"",
          "`fmt.Errorf`: \"Unexpected count for schema name: %v\"",
          "`fmt.Errorf`: \"Error converting map to SchemaRecord: %v\"",
          "`fmt.Errorf`: \"Error unmarshaling JSON: %v\"",
          "`fmt.Errorf`: \"Failed to initialize schemas collection collections %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:core.PersistenceCollectionInterface"],
          "patterns": []
        }
      },
      "persistence.Persistence.Transact": {
        "id": "method:persistence.Persistence.Transact",
        "useCase": "To execute a series of database operations within a single, atomic transaction. The provided callback function receives a transactional `PersistenceTransactionInterface` instance.",
        "signature": "func (pi *Persistence) Transact(callback func(tx core.PersistenceTransactionInterface) (any, error)) (any, error)",
        "parameters": "`callback`: `func(tx core.PersistenceTransactionInterface) (any, error)` - A function containing the transactional logic. It receives a `PersistenceTransactionInterface` and should return any result and an error. If the callback returns an error, the transaction is rolled back; otherwise, it is committed.",
        "prerequisites": "The `Persistence` instance must be initialized with a non-nil `DatabaseInteractor`.",
        "sideEffects": "Starts a new database transaction, executes the callback, and then either commits or rolls back the transaction based on the callback's return value.",
        "returnValue": "`any` - The result returned by the `callback` function. `error` - An error if the transaction fails to start, if the callback returns an error (triggering rollback), or if the commit/rollback operation fails.",
        "exceptions": [
          "`fmt.Errorf` (wrapped `error` from `DatabaseInteractor.StartTransaction`): \"failed to begin transaction\"",
          "`fmt.Errorf`: \"Failed to initialize schemas collection collections %w\"",
          "`fmt.Errorf` (wrapped `error` from callback): Error from callback.",
          "Error from `DatabaseInteractor.Rollback()` or `DatabaseInteractor.Commit()`."
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:core.PersistenceTransactionInterface"],
          "patterns": ["pattern:Transaction Management"]
        }
      },
      "persistence.Persistence.Collections": {
        "id": "method:persistence.Persistence.Collections",
        "useCase": "To retrieve a list of names of all collections (tables) managed by the Anansi persistence service.",
        "signature": "func (pi *Persistence) Collections() ([]string, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]string` - A slice of collection names. `error` - An error if retrieval fails (currently a stub, always returns empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Persistence.Create": {
        "id": "method:persistence.Persistence.Create",
        "useCase": "To create a new collection (database table) based on a provided schema definition. This also registers the schema internally within Anansi's `_schemas` collection.",
        "signature": "func (pi *Persistence) Create(schema core.SchemaDefinition) (core.PersistenceCollectionInterface, error)",
        "parameters": "`schema`: `core.SchemaDefinition` - The schema definition for the new collection.",
        "prerequisites": "The `Persistence` service must be initialized.",
        "sideEffects": "Creates a new table in the database and inserts a record into the `_schemas` collection.",
        "returnValue": "`core.PersistenceCollectionInterface` - An interface to the newly created collection. `error` - An error if the collection already exists, if table creation fails, or if schema recording fails.",
        "exceptions": [
          "`fmt.Errorf`: \"Error accessing database: %v\"",
          "`fmt.Errorf`: \"A collection with a similar name exists\"",
          "`fmt.Errorf`: \"Failed to create collection %s: %w\"",
          "`fmt.Errorf`: \"failed to marshal SchemaDefinition to JSON: %w\"",
          "`fmt.Errorf`: \"failed to marshal SchemaRecord to JSON: %w\"",
          "`fmt.Errorf`: \"failed to unmarshal JSON to map[string]any: %w\"",
          "`fmt.Errorf`: \"failed to insert data into collection '%s': %w\"",
          "`fmt.Errorf`: \"Failed to initialize schemas collection collections %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:SchemaDefinition", "type:core.PersistenceCollectionInterface"],
          "patterns": ["pattern:Collection Creation"]
        }
      },
      "persistence.Persistence.Delete": {
        "id": "method:persistence.Persistence.Delete",
        "useCase": "To delete an existing collection (database table) by its name. This also removes its schema record from Anansi's internal `_schemas` collection.",
        "signature": "func (pi *Persistence) Delete(name string) (bool, error)",
        "parameters": "`name`: `string` - The name of the collection to delete.",
        "prerequisites": "The collection must exist.",
        "sideEffects": "Drops the specified table from the database and removes its schema from the `_schemas` collection.",
        "returnValue": "`bool` - True if the collection was successfully deleted. `error` - An error if deletion fails.",
        "exceptions": [
          "`fmt.Errorf`: \"failed to begin transaction\"",
          "`fmt.Errorf`: \"Failed to initialize schemas collection collections %w\"",
          "`fmt.Errorf`: \"failed to delete data from collection '%s': %w\"",
          "`fmt.Errorf`: \"failed to drop table %s\"",
          "`fmt.Errorf`: \"Commit not applicable: not in a transactional context\"",
          "`fmt.Errorf`: \"Rollback not applicable: not in a transactional context\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Persistence.Schema": {
        "id": "method:persistence.Persistence.Schema",
        "useCase": "To retrieve the `core.SchemaDefinition` for a given collection by its name.",
        "signature": "func (pi *Persistence) Schema(name string) (*core.SchemaDefinition, error)",
        "parameters": "`name`: `string` - The name of the collection whose schema is to be retrieved.",
        "prerequisites": "The collection must exist and its schema must be recorded in the `_schemas` collection.",
        "sideEffects": "None.",
        "returnValue": "`*core.SchemaDefinition` - The schema definition. `error` - An error if the collection does not exist, or if its schema cannot be read or unmarshaled.",
        "exceptions": [
          "`fmt.Errorf`: \"Error accessing database: %v, %t\"",
          "`fmt.Errorf`: \"Collection %s does not exist: %v\"",
          "`fmt.Errorf`: \"Error reading schema collection: %v\"",
          "`fmt.Errorf`: \"Unexpected count for schema name: %v\"",
          "`fmt.Errorf`: \"Error converting map to SchemaRecord: %v\"",
          "`fmt.Errorf`: \"Error unmarshaling JSON: %v\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:SchemaDefinition"],
          "patterns": []
        }
      },
      "persistence.Persistence.Metadata": {
        "id": "method:persistence.Persistence.Metadata",
        "useCase": "To retrieve global metadata about the persistence system, such as collection counts, storage usage, and registered events/tasks. (Currently a stub)",
        "signature": "func (pi *Persistence) Metadata(filter *core.MetadataFilter, includeCollections bool, includeSchemas bool, forceRefresh bool) (core.Metadata, error)",
        "parameters": "`filter`: `*core.MetadataFilter` - Optional criteria to filter the metadata. `includeCollections`: `bool` - If true, detailed collection metadata will be included. `includeSchemas`: `bool` - If true, schema definitions will be included. `forceRefresh`: `bool` - If true, forces a refresh of metadata from the source.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`core.Metadata` - The retrieved metadata. `error` - An error if retrieval fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"Metadata method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:Metadata", "type:MetadataFilter"],
          "patterns": []
        }
      },
      "persistence.Persistence.RegisterSubscription": {
        "id": "method:persistence.Persistence.RegisterSubscription",
        "useCase": "To register a global subscription to Anansi persistence events. (Currently a stub)",
        "signature": "func (pi *Persistence) RegisterSubscription(options core.RegisterSubscriptionOptions) (core.SubscriptionInfo, error)",
        "parameters": "`options`: `core.RegisterSubscriptionOptions` - Options including the event type, label, description, and callback function.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`core.SubscriptionInfo` - Information about the registered subscription. `error` - An error if registration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"RegisterSubscription method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:RegisterSubscriptionOptions", "type:SubscriptionInfo"],
          "patterns": []
        }
      },
      "persistence.Persistence.UnregisterSubscription": {
        "id": "method:persistence.Persistence.UnregisterSubscription",
        "useCase": "To unregister a previously registered global subscription using its ID. (Currently a stub)",
        "signature": "func (pi *Persistence) UnregisterSubscription(id string) error",
        "parameters": "`id`: `string` - The ID of the subscription to unregister.",
        "prerequisites": "The subscription with the given ID must exist.",
        "sideEffects": "None.",
        "returnValue": "`error` - An error if unregistration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"UnregisterSubscription method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Persistence.RegisterTrigger": {
        "id": "method:persistence.Persistence.RegisterTrigger",
        "useCase": "To register a global trigger that executes a callback based on specific persistence events and optional conditions. (Currently a stub)",
        "signature": "func (pi *Persistence) RegisterTrigger(options core.RegisterTriggerOptions) (core.TriggerInfo, error)",
        "parameters": "`options`: `core.RegisterTriggerOptions` - Options defining the trigger's event, condition, synchronicity, label, description, and callback.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`core.TriggerInfo` - Information about the registered trigger. `error` - An error if registration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"RegisterTrigger method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:RegisterTriggerOptions", "type:TriggerInfo"],
          "patterns": []
        }
      },
      "persistence.Persistence.UnregisterTrigger": {
        "id": "method:persistence.Persistence.UnregisterTrigger",
        "useCase": "To unregister a previously registered global trigger. (Currently a stub)",
        "signature": "func (pi *Persistence) UnregisterTrigger(options core.UnregisterTriggerOptions) error",
        "parameters": "`options`: `core.UnregisterTriggerOptions` - Options specifying the trigger to unregister (by CallbackID).",
        "prerequisites": "The trigger must exist.",
        "sideEffects": "None.",
        "returnValue": "`error` - An error if unregistration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"UnregisterTrigger method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Persistence.RegisterTask": {
        "id": "method:persistence.Persistence.RegisterTask",
        "useCase": "To register a global scheduled background task that executes a callback based on a defined schedule. (Currently a stub)",
        "signature": "func (pi *Persistence) RegisterTask(options core.RegisterTaskOptions) (core.TaskInfo, error)",
        "parameters": "`options`: `core.RegisterTaskOptions` - Options defining the task's schedule, callback, synchronicity, metadata, label, and description.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`core.TaskInfo` - Information about the registered task. `error` - An error if registration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"RegisterTask method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:RegisterTaskOptions", "type:TaskInfo"],
          "patterns": []
        }
      },
      "persistence.Persistence.UnregisterTask": {
        "id": "method:persistence.Persistence.UnregisterTask",
        "useCase": "To unregister a previously registered global scheduled task. (Currently a stub)",
        "signature": "func (pi *Persistence) UnregisterTask(options core.UnregisterTaskOptions) error",
        "parameters": "`options`: `core.UnregisterTaskOptions` - Options specifying the task to unregister (by CallbackID).",
        "prerequisites": "The task must exist.",
        "sideEffects": "None.",
        "returnValue": "`error` - An error if unregistration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"UnregisterTask method stub\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Persistence.Subscriptions": {
        "id": "method:persistence.Persistence.Subscriptions",
        "useCase": "To retrieve a list of all currently registered global subscriptions. (Currently a stub)",
        "signature": "func (pi *Persistence) Subscriptions() ([]core.SubscriptionInfo, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]core.SubscriptionInfo` - A slice of `SubscriptionInfo` for all global subscriptions. `error` - An error if retrieval fails (currently always returns an empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:SubscriptionInfo"],
          "patterns": []
        }
      },
      "persistence.Persistence.Triggers": {
        "id": "method:persistence.Persistence.Triggers",
        "useCase": "To retrieve a list of all currently registered global triggers. (Currently a stub)",
        "signature": "func (pi *Persistence) Triggers() ([]core.TriggerInfo, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]core.TriggerInfo` - A slice of `TriggerInfo` for all global triggers. `error` - An error if retrieval fails (currently always returns an empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:TriggerInfo"],
          "patterns": []
        }
      },
      "persistence.Persistence.Tasks": {
        "id": "method:persistence.Persistence.Tasks",
        "useCase": "To retrieve a list of all currently registered global scheduled tasks. (Currently a stub)",
        "signature": "func (pi *Persistence) Tasks() ([]core.TaskInfo, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]core.TaskInfo` - A slice of `TaskInfo` for all global tasks. `error` - An error if retrieval fails (currently always returns an empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:TaskInfo"],
          "patterns": []
        }
      },
      "persistence.NewExecutor": {
        "id": "method:persistence.NewExecutor",
        "useCase": "To create a new `Executor` instance, which orchestrates database operations by coordinating between the `DatabaseInteractor` (for SQL execution) and `DataProcessor` (for Go-based processing).",
        "signature": "func NewExecutor(interactor persistence.DatabaseInteractor, logger *zap.Logger) *Executor",
        "parameters": "`interactor`: `persistence.DatabaseInteractor` - The low-level database interactor. `logger`: `*zap.Logger` - An optional Zap logger for executor-specific logging.",
        "prerequisites": "An initialized `persistence.DatabaseInteractor`.",
        "sideEffects": "None.",
        "returnValue": "`*Executor` - A new `Executor` instance.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:persistence.DatabaseInteractor", "type:query.DataProcessor"],
          "patterns": []
        }
      },
      "persistence.Executor.RegisterComputeFunction": {
        "id": "method:persistence.Executor.RegisterComputeFunction",
        "useCase": "To register a custom Go function (`query.ComputeFunction`) that can be used in `QueryDSL` projections to create computed fields.",
        "signature": "func (e *Executor) RegisterComputeFunction(name string, fn querydsl.ComputeFunction)",
        "parameters": "`name`: `string` - The unique name by which the compute function will be referenced in `QueryDSL`. `fn`: `querydsl.ComputeFunction` - The Go function that performs the computation.",
        "prerequisites": "None.",
        "sideEffects": "Adds the function to the internal `DataProcessor`'s registry.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:ComputeFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "persistence.Executor.RegisterFilterFunction": {
        "id": "method:persistence.Executor.RegisterFilterFunction",
        "useCase": "To register a custom Go function (`query.PredicateFunction`) that can be used in `QueryDSL` filters to perform complex in-memory filtering.",
        "signature": "func (e *Executor) RegisterFilterFunction(operator querydsl.ComparisonOperator, fn querydsl.PredicateFunction)",
        "parameters": "`operator`: `querydsl.ComparisonOperator` - The custom operator by which the filter function will be referenced in `QueryDSL`. `fn`: `querydsl.PredicateFunction` - The Go function that performs the filtering.",
        "prerequisites": "None.",
        "sideEffects": "Adds the function to the internal `DataProcessor`'s registry.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:PredicateFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "persistence.Executor.RegisterComputeFunctions": {
        "id": "method:persistence.Executor.RegisterComputeFunctions",
        "useCase": "To register multiple custom Go compute functions at once from a map.",
        "signature": "func (e *Executor) RegisterComputeFunctions(functionMap map[string]querydsl.ComputeFunction)",
        "parameters": "`functionMap`: `map[string]querydsl.ComputeFunction` - A map where keys are function names and values are `querydsl.ComputeFunction` instances.",
        "prerequisites": "None.",
        "sideEffects": "Adds functions to the internal `DataProcessor`'s registry.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:ComputeFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "persistence.Executor.RegisterFilterFunctions": {
        "id": "method:persistence.Executor.RegisterFilterFunctions",
        "useCase": "To register multiple custom Go filter functions at once from a map.",
        "signature": "func (e *Executor) RegisterFilterFunctions(functionMap map[querydsl.ComparisonOperator]querydsl.PredicateFunction)",
        "parameters": "`functionMap`: `map[querydsl.ComparisonOperator]querydsl.PredicateFunction` - A map where keys are custom `querydsl.ComparisonOperator` and values are `querydsl.PredicateFunction` instances.",
        "prerequisites": "None.",
        "sideEffects": "Adds functions to the internal `DataProcessor`'s registry.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:PredicateFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "persistence.Executor.Query": {
        "id": "method:persistence.Executor.Query",
        "useCase": "To execute a `QueryDSL` against the database, retrieve raw rows, and then apply any Go-based processing (filters, computed fields) defined in the DSL.",
        "signature": "func (e *Executor) Query(ctx context.Context, schema *core.SchemaDefinition, dsl *querydsl.QueryDSL) (*querydsl.QueryResult, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation/timeouts. `schema`: `*core.SchemaDefinition` - The schema of the collection being queried. `dsl`: `*querydsl.QueryDSL` - The declarative query object.",
        "prerequisites": "The `Executor` must be initialized with a `DatabaseInteractor` and `DataProcessor`.",
        "sideEffects": "Reads data from the database. May perform in-memory transformations.",
        "returnValue": "`*querydsl.QueryResult` - The structured query result. `error` - An error if SQL execution or Go-based processing fails.",
        "exceptions": [
          "`fmt.Errorf` (wrapped `error` from `SelectDocuments`): Error from database query.",
          "`fmt.Errorf` (wrapped `error` from `ProcessRows`): \"Go filter failed: %w\" or \"Go computed field failed: %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL", "type:QueryResult"],
          "patterns": ["pattern:Querying Documents"]
        }
      },
      "persistence.Executor.Update": {
        "id": "method:persistence.Executor.Update",
        "useCase": "To perform an update operation by delegating to the `DatabaseInteractor`.",
        "signature": "func (e *Executor) Update(ctx context.Context, schema *core.SchemaDefinition, updates map[string]any, filters *querydsl.QueryFilter) (int64, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation/timeouts. `schema`: `*core.SchemaDefinition` - The schema of the collection. `updates`: `map[string]any` - The fields to update. `filters`: `*querydsl.QueryFilter` - The filter for matching documents.",
        "prerequisites": "The `Executor` must be initialized with a `DatabaseInteractor`.",
        "sideEffects": "Updates records in the database.",
        "returnValue": "`int64` - The number of rows affected. `error` - An error if the update operation fails.",
        "exceptions": [
          "`error` from `DatabaseInteractor.UpdateDocuments()`"
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter"],
          "patterns": ["pattern:Update Documents"]
        }
      },
      "persistence.Executor.Insert": {
        "id": "method:persistence.Executor.Insert",
        "useCase": "To perform an insert operation by delegating to the `DatabaseInteractor`, returning the atomically inserted records.",
        "signature": "func (e *Executor) Insert(ctx context.Context, schema *core.SchemaDefinition, records []map[string]any) (*querydsl.QueryResult, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation/timeouts. `schema`: `*core.SchemaDefinition` - The schema of the collection. `records`: `[]map[string]any` - The records to insert.",
        "prerequisites": "The `Executor` must be initialized with a `DatabaseInteractor`.",
        "sideEffects": "Inserts records into the database.",
        "returnValue": "`*querydsl.QueryResult` - The result containing the inserted records. `error` - An error if the insert operation fails.",
        "exceptions": [
          "`error` from `DatabaseInteractor.InsertDocuments()`"
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryResult"],
          "patterns": ["pattern:Insert Single Document"]
        }
      },
      "persistence.Executor.Delete": {
        "id": "method:persistence.Executor.Delete",
        "useCase": "To perform a delete operation by delegating to the `DatabaseInteractor`.",
        "signature": "func (e *Executor) Delete(ctx context.Context, schema *core.SchemaDefinition, filters *querydsl.QueryFilter, unsafeDelete bool) (int64, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation/timeouts. `schema`: `*core.SchemaDefinition` - The schema of the collection. `filters`: `*querydsl.QueryFilter` - The filter for matching documents. `unsafeDelete`: `bool` - If true, allows deleting without a filter.",
        "prerequisites": "The `Executor` must be initialized with a `DatabaseInteractor`.",
        "sideEffects": "Deletes records from the database.",
        "returnValue": "`int64` - The number of rows affected. `error` - An error if the delete operation fails.",
        "exceptions": [
          "`error` from `DatabaseInteractor.DeleteDocuments()`"
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter"],
          "patterns": ["pattern:Delete Documents"]
        }
      },
      "persistence.NewCollection": {
        "id": "method:persistence.NewCollection",
        "useCase": "To create a new `PersistenceCollectionInterface` instance for a specific schema/collection. This function wraps the core `CollectionBase` with event emission capabilities.",
        "signature": "func NewCollection(schema *core.SchemaDefinition, executor *Executor, fmap core.FunctionMap) (core.PersistenceCollectionInterface, error)",
        "parameters": "`schema`: `*core.SchemaDefinition` - The schema definition for this collection. `executor`: `*Executor` - The executor responsible for processing queries and data operations. `fmap`: `core.FunctionMap` - A map of custom Go functions available to the collection.",
        "prerequisites": "A valid `core.SchemaDefinition` and an initialized `persistence.Executor`.",
        "sideEffects": "Initializes an event bus for the collection.",
        "returnValue": "`core.PersistenceCollectionInterface` - A new collection interface instance. `error` - An error if the event bus cannot be initialized.",
        "exceptions": [
          "`fmt.Errorf`: \"Could not initialize event bus %v\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:SchemaDefinition", "type:core.FunctionMap", "type:core.PersistenceCollectionInterface"],
          "patterns": ["pattern:Collection Creation"]
        }
      },
      "persistence.Collection.Create": {
        "id": "method:persistence.Collection.Create",
        "useCase": "To insert one or more documents into the collection. It validates the input data against the collection's schema before delegation to the executor and emits events.",
        "signature": "func (e *Collection) Create(data any) (any, error)",
        "parameters": "`data`: `any` - The document(s) to insert, either a `map[string]any` for a single document or `[]map[string]any` for batch insertion.",
        "prerequisites": "The collection must be initialized with a schema and executor.",
        "sideEffects": "Inserts data into the database. Emits `DocumentCreateStart`, `DocumentCreateSuccess`, or `DocumentCreateFailed` events.",
        "returnValue": "`any` - A `*query.QueryResult` containing the inserted document(s). `error` - An error if the data is invalid, if insertion fails at the database level, or if an event emission fails.",
        "exceptions": [
          "`fmt.Errorf`: \"invalid data type for Create: expected map[string]any or []map[string]any, got %T\"",
          "`fmt.Errorf`: \"An error occured when trying to validate an entry %e\"",
          "`fmt.Errorf`: \"Provided data does not conform to the collections schema\"",
          "`fmt.Errorf`: \"failed to insert data into collection '%s': %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:Document", "type:QueryResult"],
          "patterns": ["pattern:Insert Single Document", "pattern:Event Subscription"]
        }
      },
      "persistence.Collection.Read": {
        "id": "method:persistence.Collection.Read",
        "useCase": "To retrieve documents from the collection based on a `QueryDSL`. It delegates to the executor and emits events.",
        "signature": "func (e *Collection) Read(input any) (any, error)",
        "parameters": "`input`: `any` - The query definition, expected to be `query.QueryDSL`.",
        "prerequisites": "The collection must be initialized.",
        "sideEffects": "Reads data from the database. Emits `DocumentReadStart`, `DocumentReadSuccess`, or `DocumentReadFailed` events.",
        "returnValue": "`any` - A `*query.QueryResult` containing the fetched documents. `error` - An error if the input is not a `QueryDSL`, or if the read operation fails.",
        "exceptions": [
          "`fmt.Errorf`: \"Input to read is not a valid QueryDSL\"",
          "`fmt.Errorf`: \"failed to read data from collection '%s': %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL", "type:QueryResult"],
          "patterns": ["pattern:Querying Documents", "pattern:Event Subscription"]
        }
      },
      "persistence.Collection.Update": {
        "id": "method:persistence.Collection.Update",
        "useCase": "To update documents in the collection matching a `core.CollectionUpdate` parameter. It delegates to the executor and emits events.",
        "signature": "func (e *Collection) Update(params *core.CollectionUpdate) (int, error)",
        "parameters": "`params`: `*core.CollectionUpdate` - Parameters specifying the data to update and the filter for matching documents.",
        "prerequisites": "The collection must be initialized.",
        "sideEffects": "Updates data in the database. Emits `DocumentUpdateStart`, `DocumentUpdateSuccess`, or `DocumentUpdateFailed` events.",
        "returnValue": "`int` - The number of rows affected. `error` - An error if `params` is invalid or if the update operation fails.",
        "exceptions": [
          "`fmt.Errorf`: \"invalid params type for Update: expected query.QueryFilter, got %T\"",
          "`fmt.Errorf`: \"failed to read data from collection '%s': %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:CollectionUpdate"],
          "patterns": ["pattern:Update Documents", "pattern:Event Subscription"]
        }
      },
      "persistence.Collection.Delete": {
        "id": "method:persistence.Collection.Delete",
        "useCase": "To delete documents from the collection based on a filter. It delegates to the executor and emits events.",
        "signature": "func (e *Collection) Delete(params any, unsafe bool) (int, error)",
        "parameters": "`params`: `any` - The filter, expected to be `*query.QueryFilter`. `unsafe`: `bool` - If true, allows deleting all documents if `params` is nil.",
        "prerequisites": "The collection must be initialized.",
        "sideEffects": "Deletes data from the database. Emits `DocumentDeleteStart`, `DocumentDeleteSuccess`, or `DocumentDeleteFailed` events.",
        "returnValue": "`int` - The number of rows affected. `error` - An error if `params` is invalid or if the delete operation fails.",
        "exceptions": [
          "`fmt.Errorf`: \"invalid params type for Delete: expected query.QueryFilter, got %T\"",
          "`fmt.Errorf`: \"failed to delete data from collection '%s': %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter"],
          "patterns": ["pattern:Delete Documents", "pattern:Event Subscription"]
        }
      },
      "persistence.Collection.Validate": {
        "id": "method:persistence.Collection.Validate",
        "useCase": "To validate a given data object against the collection's schema definition.",
        "signature": "func (e *Collection) Validate(data any, loose bool) (*core.ValidationResult, error)",
        "parameters": "`data`: `any` - The data to validate, expected to be `map[string]any`. `loose`: `bool` - If true, `REQUIRED_FIELD_MISSING` issues will be ignored.",
        "prerequisites": "The collection must be initialized with a schema and validator.",
        "sideEffects": "None.",
        "returnValue": "`*core.ValidationResult` - The result of the validation, indicating validity and listing issues. `error` - An error if the input data cannot be converted to a map.",
        "exceptions": [
          "`fmt.Errorf`: \"Failed to convert data to a map\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:ValidationResult"],
          "patterns": []
        }
      },
      "persistence.Collection.Rollback": {
        "id": "method:persistence.Collection.Rollback",
        "useCase": "To roll back the collection's schema to a previous version. (Currently a stub)",
        "signature": "func (e *Collection) Rollback(version *string, dryRun *bool) (struct { Schema core.SchemaDefinition `json:\"schema\"`; Preview any `json:\"preview\"` }, error)",
        "parameters": "`version`: `*string` - The target schema version to roll back to. `dryRun`: `*bool` - If true, performs a dry run without actual changes.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "Anonymous struct containing schema and preview of changes. `error` - An error if rollback fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"Rollback method stub for collection '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:SchemaDefinition"],
          "patterns": []
        }
      },
      "persistence.Collection.Migrate": {
        "id": "method:persistence.Collection.Migrate",
        "useCase": "To migrate the collection's schema to a new version, potentially transforming existing data. (Currently a stub)",
        "signature": "func (e *Collection) Migrate(description string, cb func(h core.SchemaMigrationHelper) (core.DataTransform[any, any], error), dryRun *bool) (struct { Schema core.SchemaDefinition `json:\"schema\"`; Preview any `json:\"preview\"` }, error)",
        "parameters": "`description`: `string` - A description of the migration. `cb`: `func(h core.SchemaMigrationHelper) (core.DataTransform[any, any], error)` - A callback function that defines the schema changes and data transformations. `dryRun`: `*bool` - If true, performs a dry run.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "Anonymous struct containing schema and preview of changes. `error` - An error if migration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"Migrate method stub for collection '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:SchemaDefinition"],
          "patterns": []
        }
      },
      "persistence.Collection.Metadata": {
        "id": "method:persistence.Collection.Metadata",
        "useCase": "To retrieve metadata specific to this collection, such as record count, storage usage, and collection-scoped registered events/tasks. (Currently a stub)",
        "signature": "func (e *Collection) Metadata(filter *core.MetadataFilter, forceRefresh bool) (core.Metadata, error)",
        "parameters": "`filter`: `*core.MetadataFilter` - Optional criteria to filter the metadata. `forceRefresh`: `bool` - If true, forces a refresh of metadata.",
        "prerequisites": "None.",
        "sideEffects": "Emits a `metadata:called` telemetry event.",
        "returnValue": "`core.Metadata` - The retrieved collection-specific metadata. `error` - An error if retrieval fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"Collection metadata method stub for '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:Metadata", "type:MetadataFilter"],
          "patterns": []
        }
      },
      "persistence.Collection.RegisterSubscription": {
        "id": "method:persistence.Collection.RegisterSubscription",
        "useCase": "To register a new collection-scoped subscription to specific persistence events. The callback function will be invoked when the specified event occurs for this collection.",
        "signature": "func (e *Collection) RegisterSubscription(options core.RegisterSubscriptionOptions) string",
        "parameters": "`options`: `core.RegisterSubscriptionOptions` - Options defining the event type, label, description, and callback function for the subscription.",
        "prerequisites": "None.",
        "sideEffects": "Adds the subscription to the collection's event bus. Emits a `subscription:register` event.",
        "returnValue": "`string` - A unique ID for the registered subscription, which can be used for unregistration.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:RegisterSubscriptionOptions", "type:SubscriptionInfo"],
          "patterns": ["pattern:Event Subscription"]
        }
      },
      "persistence.Collection.UnregisterSubscription": {
        "id": "method:persistence.Collection.UnregisterSubscription",
        "useCase": "To unregister a previously registered collection-scoped subscription using its ID.",
        "signature": "func (e *Collection) UnregisterSubscription(id string)",
        "parameters": "`id`: `string` - The ID of the subscription to unregister, obtained from `RegisterSubscription`.",
        "prerequisites": "The subscription with the given ID must exist.",
        "sideEffects": "Removes the subscription from the collection's event bus. Emits a `subscription:unregister` event.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": ["pattern:Event Subscription"]
        }
      },
      "persistence.Collection.RegisterTrigger": {
        "id": "method:persistence.Collection.RegisterTrigger",
        "useCase": "To register a collection-scoped trigger that executes a callback based on specific persistence events and optional conditions. (Currently a stub)",
        "signature": "func (e *Collection) RegisterTrigger(options core.RegisterTriggerOptions) (core.TriggerInfo, error)",
        "parameters": "`options`: `core.RegisterTriggerOptions` - Options defining the trigger's event, condition, synchronicity, label, description, and callback.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`core.TriggerInfo` - Information about the registered trigger. `error` - An error if registration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"RegisterTrigger method stub for collection '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:RegisterTriggerOptions", "type:TriggerInfo"],
          "patterns": []
        }
      },
      "persistence.Collection.UnregisterTrigger": {
        "id": "method:persistence.Collection.UnregisterTrigger",
        "useCase": "To unregister a previously registered collection-scoped trigger. (Currently a stub)",
        "signature": "func (e *Collection) UnregisterTrigger(options core.UnregisterTriggerOptions) error",
        "parameters": "`options`: `core.UnregisterTriggerOptions` - Options specifying the trigger to unregister (by CallbackID).",
        "prerequisites": "The trigger must exist.",
        "sideEffects": "None.",
        "returnValue": "`error` - An error if unregistration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"UnregisterTrigger method stub for collection '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Collection.RegisterTask": {
        "id": "method:persistence.Collection.RegisterTask",
        "useCase": "To register a collection-scoped scheduled background task that executes a callback based on a defined schedule. (Currently a stub)",
        "signature": "func (e *Collection) RegisterTask(options core.RegisterTaskOptions) (core.TaskInfo, error)",
        "parameters": "`options`: `core.RegisterTaskOptions` - Options defining the task's schedule, callback, synchronicity, metadata, label, and description.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`core.TaskInfo` - Information about the registered task. `error` - An error if registration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"RegisterTask method stub for collection '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:RegisterTaskOptions", "type:TaskInfo"],
          "patterns": []
        }
      },
      "persistence.Collection.UnregisterTask": {
        "id": "method:persistence.Collection.UnregisterTask",
        "useCase": "To unregister a previously registered collection-scoped scheduled task. (Currently a stub)",
        "signature": "func (e *Collection) UnregisterTask(options core.UnregisterTaskOptions) error",
        "parameters": "`options`: `core.UnregisterTaskOptions` - Options specifying the task to unregister (by CallbackID).",
        "prerequisites": "The task must exist.",
        "sideEffects": "None.",
        "returnValue": "`error` - An error if unregistration fails (currently always returns a stub error).",
        "exceptions": [
          "`fmt.Errorf`: \"UnregisterTask method stub for collection '%s'\""
        ],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "persistence.Collection.Subscriptions": {
        "id": "method:persistence.Collection.Subscriptions",
        "useCase": "To retrieve a list of all currently registered collection-scoped subscriptions. (Currently a stub)",
        "signature": "func (e *Collection) Subscriptions() ([]core.SubscriptionInfo, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]core.SubscriptionInfo` - A slice of `SubscriptionInfo` for all collection-scoped subscriptions. `error` - An error if retrieval fails (currently always returns an empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:SubscriptionInfo"],
          "patterns": []
        }
      },
      "persistence.Collection.Triggers": {
        "id": "method:persistence.Collection.Triggers",
        "useCase": "To retrieve a list of all currently registered collection-scoped triggers. (Currently a stub)",
        "signature": "func (e *Collection) Triggers() ([]core.TriggerInfo, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]core.TriggerInfo` - A slice of `TriggerInfo` for all collection-scoped triggers. `error` - An error if retrieval fails (currently always returns an empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:TriggerInfo"],
          "patterns": []
        }
      },
      "persistence.Collection.Tasks": {
        "id": "method:persistence.Collection.Tasks",
        "useCase": "To retrieve a list of all currently registered collection-scoped scheduled tasks. (Currently a stub)",
        "signature": "func (e *Collection) Tasks() ([]core.TaskInfo, error)",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`[]core.TaskInfo` - A slice of `TaskInfo` for all collection-scoped tasks. `error` - An error if retrieval fails (currently always returns an empty slice and nil error).",
        "exceptions": [],
        "availability": "sync",
        "status": "stubbed",
        "related": {
          "types": ["type:TaskInfo"],
          "patterns": []
        }
      },
      "query.NewQueryBuilder": {
        "id": "method:query.NewQueryBuilder",
        "useCase": "To create a new `QueryBuilder` instance, which provides a fluent API for constructing `QueryDSL` objects.",
        "signature": "func NewQueryBuilder() *QueryBuilder",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`*QueryBuilder` - A new `QueryBuilder` instance, initialized with an empty `QueryDSL`.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL"],
          "patterns": ["pattern:Querying Documents"]
        }
      },
      "query.QueryBuilder.Build": {
        "id": "method:query.QueryBuilder.Build",
        "useCase": "To finalize the query construction and return the resulting `QueryDSL` object.",
        "signature": "func (qb *QueryBuilder) Build() QueryDSL",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`QueryDSL` - The constructed declarative query object.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL"],
          "patterns": ["pattern:Querying Documents"]
        }
      },
      "query.QueryBuilder.Clone": {
        "id": "method:query.QueryBuilder.Clone",
        "useCase": "To create a deep copy of the current `QueryBuilder` instance, allowing modifications to the copy without affecting the original.",
        "signature": "func (qb *QueryBuilder) Clone() *QueryBuilder",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`*QueryBuilder` - A new `QueryBuilder` instance with a deep copy of the original `QueryDSL`.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "query.QueryBuilder.Reset": {
        "id": "method:query.QueryBuilder.Reset",
        "useCase": "To clear all configured query parameters and return the `QueryBuilder` to its initial, empty state.",
        "signature": "func (qb *QueryBuilder) Reset() *QueryBuilder",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "Resets the internal `QueryDSL` to an empty state.",
        "returnValue": "`*QueryBuilder` - The current `QueryBuilder` instance, for chaining.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "query.QueryBuilder.Validate": {
        "id": "method:query.QueryBuilder.Validate",
        "useCase": "To perform comprehensive validation of the constructed `QueryDSL` for common logical errors and inconsistencies (e.g., both include and exclude projections).",
        "signature": "func (qb *QueryBuilder) Validate() ValidationResult",
        "parameters": "None.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`ValidationResult` - An object indicating whether the query is valid (`IsValid` field) and a slice of `ValidationError`s if not.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "query.DataProcessor.NewDataProcessor": {
        "id": "method:query.DataProcessor.NewDataProcessor",
        "useCase": "To create a new `DataProcessor` instance, which is responsible for applying Go-based data transformations, filtering, and projections on `query.Document` slices.",
        "signature": "func NewDataProcessor(logger *zap.Logger) *DataProcessor",
        "parameters": "`logger`: `*zap.Logger` - An optional Zap logger for data processor-specific logging.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`*DataProcessor` - A new `DataProcessor` instance.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "query.DataProcessor.RegisterComputeFunction": {
        "id": "method:query.DataProcessor.RegisterComputeFunction",
        "useCase": "To register a custom Go function for computed fields. This function will be available for use in `QueryDSL` projections.",
        "signature": "func (p *DataProcessor) RegisterComputeFunction(name string, fn ComputeFunction)",
        "parameters": "`name`: `string` - The unique name for the compute function. `fn`: `ComputeFunction` - The Go function that performs the computation.",
        "prerequisites": "None.",
        "sideEffects": "Adds the function to the `DataProcessor`'s internal map of compute functions.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:ComputeFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "query.DataProcessor.RegisterFilterFunction": {
        "id": "method:query.DataProcessor.RegisterFilterFunction",
        "useCase": "To register a custom Go function for in-memory filtering logic. This function can be used with custom comparison operators in `QueryDSL` filters.",
        "signature": "func (p *DataProcessor) RegisterFilterFunction(operator ComparisonOperator, fn PredicateFunction)",
        "parameters": "`operator`: `ComparisonOperator` - The custom comparison operator associated with this filter function. `fn`: `PredicateFunction` - The Go function that performs the filtering.",
        "prerequisites": "None.",
        "sideEffects": "Adds the function to the `DataProcessor`'s internal map of filter functions.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:PredicateFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "query.DataProcessor.RegisterComputeFunctions": {
        "id": "method:query.DataProcessor.RegisterComputeFunctions",
        "useCase": "To register multiple custom Go compute functions from a map. This is a convenience method for batch registration.",
        "signature": "func (p *DataProcessor) RegisterComputeFunctions(functionMap map[string]ComputeFunction)",
        "parameters": "`functionMap`: `map[string]ComputeFunction` - A map of function names to `ComputeFunction` instances.",
        "prerequisites": "None.",
        "sideEffects": "Adds functions to the `DataProcessor`'s internal map of compute functions.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:ComputeFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "query.DataProcessor.RegisterFilterFunctions": {
        "id": "method:query.DataProcessor.RegisterFilterFunctions",
        "useCase": "To register multiple custom Go filter functions from a map. This is a convenience method for batch registration.",
        "signature": "func (p *DataProcessor) RegisterFilterFunctions(functionMap map[ComparisonOperator]PredicateFunction)",
        "parameters": "`functionMap`: `map[ComparisonOperator]PredicateFunction` - A map of custom comparison operators to `PredicateFunction` instances.",
        "prerequisites": "None.",
        "sideEffects": "Adds functions to the `DataProcessor`'s internal map of filter functions.",
        "returnValue": "None",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:PredicateFunction"],
          "patterns": ["pattern:Using Go Functions"]
        }
      },
      "query.DataProcessor.DetermineFieldsToSelect": {
        "id": "method:query.DataProcessor.DetermineFieldsToSelect",
        "useCase": "To analyze a `QueryDSL` and identify all fields that need to be fetched from the database, including fields required for Go-based computed fields or custom filters.",
        "signature": "func (p *DataProcessor) DetermineFieldsToSelect(dsl *QueryDSL) []ProjectionField",
        "parameters": "`dsl`: `*QueryDSL` - The declarative query object to analyze.",
        "prerequisites": "Registered Go compute and filter functions (if any are used in the `dsl`).",
        "sideEffects": "None.",
        "returnValue": "`[]ProjectionField` - A slice of `ProjectionField`s representing all fields that should be selected from the database to satisfy the `QueryDSL`.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryDSL", "type:ProjectionField"],
          "patterns": []
        }
      },
      "query.DataProcessor.ProcessRows": {
        "id": "method:query.DataProcessor.ProcessRows",
        "useCase": "To apply all Go-based transformations (custom filters, computed fields, and final projection) to a slice of `query.Document`s retrieved from the database.",
        "signature": "func (p *DataProcessor) ProcessRows(rows []Document, dsl *QueryDSL, skippedOperators []ComparisonOperator) ([]Document, error)",
        "parameters": "`rows`: `[]Document` - The slice of raw documents fetched from the database. `dsl`: `*QueryDSL` - The original declarative query object. `skippedOperators`: `[]ComparisonOperator` - A list of standard comparison operators that were already handled by the database (e.g., in the SQL `WHERE` clause) and should not be re-evaluated by Go filters.",
        "prerequisites": "The `DataProcessor` must be initialized, and any necessary Go functions must be registered.",
        "sideEffects": "Transforms the input `rows` in-memory. May filter out rows or add new fields.",
        "returnValue": "`[]Document` - The processed slice of documents. `error` - An error if any Go-based filter or compute function fails.",
        "exceptions": [
          "`fmt.Errorf`: \"Go filter failed: %w\"",
          "`fmt.Errorf`: \"Go computed field failed: %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:Document", "type:QueryDSL"],
          "patterns": []
        }
      },
      "query.DataProcessor.Match": {
        "id": "method:query.DataProcessor.Match",
        "useCase": "To evaluate a single `query.Document` against a set of `QueryFilter` conditions using the registered Go-based filter functions. Useful for applying query logic to in-memory data.",
        "signature": "func (p *DataProcessor) Match(ctx context.Context, filters *QueryFilter, data Document) (bool, error)",
        "parameters": "`ctx`: `context.Context` - Context for cancellation/timeouts. `filters`: `*QueryFilter` - The filter conditions to evaluate. `data`: `Document` - The single document to match against the filters.",
        "prerequisites": "Any custom Go filter functions used in `filters` must be registered with the `DataProcessor`.",
        "sideEffects": "None.",
        "returnValue": "`bool` - True if the `data` matches the `filters`, false otherwise. `error` - An error if a registered Go filter function is not found or fails during evaluation.",
        "exceptions": [
          "`fmt.Errorf`: \"error evaluating Go filter for row %+v: %w\""
        ],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:QueryFilter", "type:Document"],
          "patterns": []
        }
      },
      "core.NewValidator": {
        "id": "method:core.NewValidator",
        "useCase": "To create a new `Validator` instance configured with a `SchemaDefinition` and a map of custom predicate functions.",
        "signature": "func NewValidator(schema *SchemaDefinition, fmap FunctionMap) *Validator",
        "parameters": "`schema`: `*SchemaDefinition` - The schema against which data will be validated. `fmap`: `FunctionMap` - A map of custom predicate functions available for `Constraint`s.",
        "prerequisites": "A valid `SchemaDefinition` and `FunctionMap` (can be empty).",
        "sideEffects": "None.",
        "returnValue": "`*Validator` - A new `Validator` instance.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:SchemaDefinition", "type:core.FunctionMap"],
          "patterns": []
        }
      },
      "core.Validator.Validate": {
        "id": "method:core.Validator.Validate",
        "useCase": "To validate a given `map[string]any` data object against the validator's configured `SchemaDefinition`, including field types, required fields, and custom constraints.",
        "signature": "func (v *Validator) Validate(data map[string]any, loose bool) (bool, []Issue)",
        "parameters": "`data`: `map[string]any` - The data object to validate. `loose`: `bool` - If true, `REQUIRED_FIELD_MISSING` issues are ignored, making validation more permissive.",
        "prerequisites": "The `Validator` instance must be initialized with a schema.",
        "sideEffects": "Resets internal `issues` slice for each run.",
        "returnValue": "`bool` - True if validation passes (or passes in loose mode), false otherwise. `[]Issue` - A slice of `Issue` structs detailing all validation failures.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": ["type:ValidationResult", "type:Issue"],
          "patterns": []
        }
      },
      "core.StringPtr": {
        "id": "method:core.StringPtr",
        "useCase": "A utility function to return a pointer to a string literal. Useful for fields that are `*string` in Go structs but conceptually accept string literals.",
        "signature": "func StringPtr(s string) *string",
        "parameters": "`s`: `string` - The string value.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`*string` - A pointer to the input string.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "core.Int64Ptr": {
        "id": "method:core.Int64Ptr",
        "useCase": "A utility function to return a pointer to an `int64` value. Useful for fields that are `*int64` in Go structs.",
        "signature": "func Int64Ptr(i int64) *int64",
        "parameters": "`i`: `int64` - The `int64` value.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`*int64` - A pointer to the input `int64`.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "core.BoolPtr": {
        "id": "method:core.BoolPtr",
        "useCase": "A utility function to return a pointer to a boolean value. Useful for fields that are `*bool` in Go structs.",
        "signature": "func BoolPtr(b bool) *bool",
        "parameters": "`b`: `bool` - The boolean value.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`*bool` - A pointer to the input boolean.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      },
      "core.ToFloat64": {
        "id": "method:core.ToFloat64",
        "useCase": "A utility function to attempt converting an `any` type value to `float64`. It handles various numeric types and string representations.",
        "signature": "func ToFloat64(v interface{}) (float64, bool)",
        "parameters": "`v`: `interface{}` - The value to convert.",
        "prerequisites": "None.",
        "sideEffects": "None.",
        "returnValue": "`float64` - The converted `float64` value. `bool` - True if conversion was successful, false otherwise.",
        "exceptions": [],
        "availability": "sync",
        "status": "active",
        "related": {
          "types": [],
          "patterns": []
        }
      }
    },
    "decisionTrees": {
      "TransactionalOperations": {
        "id": "decisionTree:TransactionalOperations",
        "question": "Should a series of database operations be atomic (all succeed or all fail)?",
        "logic": "IF [multiple interdependent database operations] AND [atomicity is required] THEN [wrap operations in `persistence.Persistence.Transact()`] ELSE [execute operations individually]",
        "validationMethod": "Observe the database state after the operation: if an error occurred within the `Transact` callback, no changes should be visible; if successful, all changes should be present. Check logs for transaction commit/rollback messages.",
        "related": {
          "methods": [
            "method:persistence.Persistence.Transact",
            "method:sqlite.SQLiteInteractor.StartTransaction",
            "method:sqlite.SQLiteInteractor.Commit",
            "method:sqlite.SQLiteInteractor.Rollback"
          ],
          "patterns": [
            "pattern:Transaction Management"
          ]
        }
      },
      "CollectionDeletionSafety": {
        "id": "decisionTree:CollectionDeletionSafety",
        "question": "Should all documents in a collection be deleted, or only a subset?",
        "logic": "IF [only a subset of documents needs to be deleted] THEN [provide a precise `query.QueryFilter` to `collection.Delete()` with `unsafe` set to `false`] ELSE IF [all documents in the collection need to be deleted AND user acknowledges the risk] THEN [call `collection.Delete(nil, true)`] ELSE [do not proceed with deletion without a filter].",
        "validationMethod": "After deletion, perform a `collection.Read()` to verify the remaining documents. Check the `int` return value (rows affected) from `collection.Delete()`.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.Delete",
            "method:sqlite.SQLiteInteractor.DeleteDocuments"
          ],
          "patterns": [
            "pattern:Delete Documents"
          ]
        }
      },
      "SchemaValidationFailure": {
        "id": "decisionTree:SchemaValidationFailure",
        "question": "Data validation failed against the schema during a Create/Update operation. How to diagnose and resolve?",
        "logic": "IF [`collection.Create()` or `collection.Update()` returns an error indicating schema non-conformance] THEN [call `collection.Validate(data, false)` on the input data to get detailed `ValidationResult.Issues`]; IF [issues include `REQUIRED_FIELD_MISSING`] THEN [add missing required fields to data] ELSE IF [issues include `TYPE_MISMATCH`] THEN [correct data types] ELSE IF [issues include `CONSTRAINT_VIOLATION` or `ENUM_VIOLATION`] THEN [adjust data to meet constraints or review constraint definitions].",
        "validationMethod": "Re-run `collection.Validate(data, false)` after corrections. The `Valid` field should be `true` and `Issues` slice empty. Then retry the `Create` or `Update` operation.",
        "related": {
          "methods": [
            "method:core.PersistenceCollectionInterface.Validate",
            "method:persistence.Collection.Validate",
            "method:core.Validator.Validate"
          ],
          "patterns": []
        }
      }
    },
    "patterns": {
      "SchemaDefinitionPattern": {
        "id": "pattern:SchemaDefinitionPattern",
        "description": "Defines the structure of a data collection using a `core.SchemaDefinition` struct, typically unmarshaled from JSON. It specifies fields, types, constraints, and indexes.",
        "example": {
          "code": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n)\n\nfunc defineSchema() (*core.SchemaDefinition, error) {\n\tuserSchemaJSON := `{\n\t\t\"name\": \"users\",\n\t\t\"version\": \"1.0.0\",\n\t\t\"description\": \"Schema for user profiles\",\n\t\t\"fields\": {\n\t\t\t\"id\": {\"name\": \"id\", \"type\": \"integer\", \"unique\": true},\n\t\t\t\"name\": {\"name\": \"name\", \"type\": \"string\", \"required\": true},\n\t\t\t\"email\": {\"name\": \"email\", \"type\": \"string\", \"required\": true, \"unique\": true},\n\t\t\t\"age\": {\"name\": \"age\", \"type\": \"integer\", \"required\": false},\n\t\t\t\"is_active\": {\"name\": \"is_active\", \"type\": \"boolean\", \"required\": true, \"default\": true}\n\t\t},\n\t\t\"indexes\": [\n\t\t\t{\"name\": \"pk_user_id\", \"fields\": [\"id\"], \"type\": \"primary\"},\n\t\t\t{\"name\": \"idx_user_email\", \"fields\": [\"email\"], \"type\": \"unique\"}\n\t\t]\n\t}`\n\n\tvar userSchema core.SchemaDefinition\n\terr := json.Unmarshal([]byte(userSchemaJSON), &userSchema)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to unmarshal user schema JSON: %w\", err)\n\t}\n\tfmt.Println(\"Schema defined successfully.\")\n\treturn &userSchema, nil\n}\n",
          "validation": "The `userSchema` variable will contain a valid `core.SchemaDefinition` struct, parsed from the JSON string. No error should be returned."
        },
        "related": {
          "methods": [
            "method:persistence.Persistence.Create"
          ],
          "errors": [
            "error:Failed to unmarshal user schema JSON"
          ]
        }
      },
      "PersistenceInitialization": {
        "id": "pattern:PersistenceInitialization",
        "description": "Establishes the connection to the database and initializes the Anansi `Persistence` service, preparing it for schema and data operations.",
        "example": {
          "code": "package main\n\nimport (\n\t\"database/sql\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n\t\"github.com/asaidimu/go-anansi/sqlite\"\n\t_ \"github.com/mattn/go-sqlite3\" // SQLite driver\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Ensure a clean start by removing the database file if it exists\n\tif err := os.Remove(\"app.db\"); err != nil && !os.IsNotExist(err) {\n\t\tlog.Fatalf(\"Failed to remove existing database file: %v\", err)\n\t}\n\n\t// Open a standard SQL database connection\n\tdb, err := sql.Open(\"sqlite3\", \"app.db\")\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to open database connection: %v\", err)\n\t}\n\tdefer func() {\n\t\tif cErr := db.Close(); cErr != nil {\n\t\t\tlog.Printf(\"Error closing database connection: %v\", cErr)\n\t\t}\n\t}()\n\n\t// Initialize a Zap logger (or zap.NewNop() for silent operation)\n\tlogger := zap.NewDevelopment() // Use zap.NewNop() for production if verbose logging is not desired\n\tdefer func() { _ = logger.Sync() }() // Ensure buffered logs are flushed\n\n\t// Create the SQLite-specific interactor\n\tinteractor := sqlite.NewSQLiteInteractor(db, logger, nil, nil)\n\n\t// Initialize the Anansi persistence service\n\tpersistenceSvc, err := persistence.NewPersistence(interactor, core.FunctionMap{})\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to initialize persistence: %v\", err)\n\t}\n\tfmt.Println(\"Persistence service initialized successfully.\")\n}\n",
          "validation": "The `persistenceSvc` variable will hold a non-nil `*persistence.Persistence` instance, indicating successful initialization. No fatal errors should be logged."
        },
        "related": {
          "methods": [
            "method:sqlite.NewSQLiteInteractor",
            "method:persistence.NewPersistence"
          ],
          "errors": [
            "error:Failed to open database connection",
            "error:Failed to initialize schemas collection collections"
          ]
        }
      },
      "CollectionCreation": {
        "id": "pattern:CollectionCreation",
        "description": "Defines a schema for a new data collection (logical table) and creates the corresponding physical table in the database through the Anansi persistence service.",
        "example": {
          "code": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n)\n\n// Assume 'persistenceSvc' is an initialized *persistence.Persistence\nfunc createMyCollection(persistenceSvc *persistence.Persistence) (core.PersistenceCollectionInterface, error) {\n\tmySchemaJSON := `{\"name\": \"products\", \"version\": \"1.0.0\", \"fields\": {\"id\": {\"type\": \"integer\", \"unique\": true}, \"name\": {\"type\": \"string\", \"required\": true}}, \"indexes\": [{\"name\": \"pk_product_id\", \"fields\": [\"id\"], \"type\": \"primary\"}]}`\n\tvar mySchema core.SchemaDefinition\n\tif err := json.Unmarshal([]byte(mySchemaJSON), &mySchema); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to unmarshal schema JSON: %w\", err)\n\t}\n\n\tcollection, err := persistenceSvc.Create(mySchema)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create collection: %w\", err)\n\t}\n\tfmt.Printf(\"Collection '%s' created successfully.\\n\", mySchema.Name)\n\treturn collection, nil\n}\n",
          "validation": "The returned `collection` variable will be a non-nil `core.PersistenceCollectionInterface` instance. The database should contain a table named `products` (or whatever `TablePrefix` is configured)."
        },
        "related": {
          "methods": [
            "method:persistence.Persistence.Create",
            "method:sqlite.SQLiteInteractor.CreateCollection"
          ],
          "errors": [
            "error:A collection with a similar name exists",
            "error:Failed to create collection"
          ]
        }
      },
      "Insert Single Document": {
        "id": "pattern:Insert Single Document",
        "description": "Inserts a single document (record) into an existing collection. The document is provided as a `map[string]any` and is validated against the collection's schema.",
        "example": {
          "code": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface for the 'users' schema\nfunc insertOneUser(collection core.PersistenceCollectionInterface) {\n\tuser := map[string]any{\n\t\t\"name\":      \"Alice Smith\",\n\t\t\"email\":     \"alice@example.com\",\n\t\t\"age\":       30,\n\t\t\"is_active\": true,\n\t}\n\n\tresult, err := collection.Create(user)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to insert user: %v\", err)\n\t}\n\n\tinsertedUser := result.(*query.QueryResult).Data.(query.Document)\n\tfmt.Printf(\"Inserted user with ID: %v and Name: %s\\n\", insertedUser[\"id\"], insertedUser[\"name\"])\n}\n",
          "validation": "The `result` will be a `*query.QueryResult` where `result.Data` contains the inserted `query.Document`, including any auto-generated fields like `id`. The `err` will be `nil`."
        },
        "related": {
          "methods": [
            "method:persistence.Collection.Create",
            "method:persistence.Executor.Insert",
            "method:sqlite.SQLiteInteractor.InsertDocuments"
          ],
          "errors": [
            "error:Provided data does not conform to the collections schema",
            "error:failed to insert data"
          ]
        }
      },
      "Read All Documents": {
        "id": "pattern:Read All Documents",
        "description": "Retrieves all documents from a collection without any filters, sorting, or pagination. It's a basic read operation.",
        "example": {
          "code": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc readAllUsers(collection core.PersistenceCollectionInterface) {\n\t// Create an empty query DSL to read all documents\n\tq := query.NewQueryBuilder().Build()\n\n\tresult, err := collection.Read(q)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to read all users: %v\", err)\n\t}\n\n\tusers := result.(*query.QueryResult).Data.([]query.Document)\n\tfmt.Printf(\"Found %d users:\\n\", len(users))\n\tfor _, user := range users {\n\t\tfmt.Printf(\"  ID: %v, Name: %v, Email: %v\\n\", user[\"id\"], user[\"name\"], user[\"email\"])\n\t}\n}\n",
          "validation": "The `result` will be a `*query.QueryResult` where `result.Data` is `[]query.Document` containing all documents from the collection. The `err` will be `nil`."
        },
        "related": {
          "methods": [
            "method:persistence.Collection.Read",
            "method:persistence.Executor.Query",
            "method:sqlite.SQLiteInteractor.SelectDocuments"
          ],
          "errors": [
            "error:failed to read data from collection"
          ]
        }
      },
      "Update Documents": {
        "id": "pattern:Update Documents",
        "description": "Modifies existing documents in a collection that match a specified filter. The changes are provided as a `map[string]any`.",
        "example": {
          "code": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc updateUsers(collection core.PersistenceCollectionInterface) {\n\t// Define the updates: change 'age' to 31\n\tupdates := map[string]any{\"age\": 31}\n\n\t// Define the filter: update users with 'email' 'alice@example.com'\n\tfilter := query.NewQueryBuilder().Where(\"email\").Eq(\"alice@example.com\").Build().Filters\n\n\tupdateParams := &core.CollectionUpdate{\n\t\tData:   updates,\n\t\tFilter: filter,\n\t}\n\n\trowsAffected, err := collection.Update(updateParams)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to update user: %v\", err)\n\t}\n\tfmt.Printf(\"Updated %d rows.\\n\", rowsAffected)\n}\n",
          "validation": "The `rowsAffected` variable will be an `int` indicating the number of documents successfully updated. The `err` will be `nil`. You can verify by performing a `Read` operation on the updated documents."
        },
        "related": {
          "methods": [
            "method:persistence.Collection.Update",
            "method:persistence.Executor.Update",
            "method:sqlite.SQLiteInteractor.UpdateDocuments"
          ],
          "errors": [
            "error:failed to read data from collection"
          ]
        }
      },
      "Delete Documents": {
        "id": "pattern:Delete Documents",
        "description": "Removes documents from a collection based on a specified filter. Anansi enforces safety by requiring a filter unless `unsafe` is explicitly set to `true`.",
        "example": {
          "code": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc deleteInactiveUsers(collection core.PersistenceCollectionInterface) {\n\t// Define the filter: delete users where 'is_active' is false\n\tfilter := query.NewQueryBuilder().Where(\"is_active\").Eq(false).Build().Filters\n\n\t// Perform the delete operation. 'false' means a filter is required.\n\trowsAffected, err := collection.Delete(filter, false)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to delete inactive users: %v\", err)\n\t}\n\tfmt.Printf(\"Deleted %d inactive users.\\n\", rowsAffected)\n\n\t// To delete ALL documents (use with extreme caution!)\n\t// allRowsAffected, err := collection.Delete(nil, true)\n\t// if err != nil { log.Fatalf(\"Failed to delete all users: %v\", err) }\n\t// fmt.Printf(\"Deleted %d all users.\\n\", allRowsAffected)\n}\n",
          "validation": "The `rowsAffected` variable will be an `int` indicating the number of documents successfully deleted. The `err` will be `nil`. Verify by performing a `Read` operation on the collection."
        },
        "related": {
          "methods": [
            "method:persistence.Collection.Delete",
            "method:persistence.Executor.Delete",
            "method:sqlite.SQLiteInteractor.DeleteDocuments"
          ],
          "errors": [
            "error:DELETE without WHERE clause is not allowed for safety",
            "error:failed to delete data from collection"
          ]
        }
      },
      "Querying Documents": {
        "id": "pattern:Querying Documents",
        "description": "Constructs and executes complex queries using the `query.QueryBuilder` fluent API, allowing for advanced filtering, sorting, pagination, and projection.",
        "example": {
          "code": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc queryActiveUsers(collection core.PersistenceCollectionInterface) {\n\tqueryDSL := query.NewQueryBuilder().\n\t\t// Filter for active users with age between 25 and 35\n\t\tWhereGroup(query.LogicalOperatorAnd).\n\t\t\tWhere(\"is_active\").Eq(true).\n\t\t\tWhere(\"age\").Gte(25).\n\t\t\tWhere(\"age\").Lte(35).\n\t\tEnd().\n\t\t// Order by name ascending, then age descending\n\t\tOrderByAsc(\"name\").\n\t\tOrderByDesc(\"age\").\n\t\t// Paginate: get 2 results, starting from the 0th offset\n\t\tLimit(2).Offset(0). // Note: Cursor-based pagination is conceptual in QueryDSL for now\n\t\t// Select only 'id', 'name', and 'email' fields\n\t\tSelect().\n\t\t\tInclude(\"id\", \"name\", \"email\").\n\t\tEnd().\n\t\tBuild()\n\n\tresult, err := collection.Read(queryDSL)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to query active users: %v\", err)\n\t}\n\n\tusers := result.(*query.QueryResult).Data.([]query.Document)\n\tfmt.Println(\"\\n--- Active Users (25-35, sorted, paginated, projected) ---\")\n\tfor _, user := range users {\n\t\tfmt.Printf(\"  ID: %v, Name: %v, Email: %v\\n\", user[\"id\"], user[\"name\"], user[\"email\"])\n\t}\n}\n",
          "validation": "The `result` will be a `*query.QueryResult` containing documents that match all specified criteria, ordered and paginated as requested. The `Data` field will only contain the 'id', 'name', and 'email' fields. The `err` will be `nil`."
        },
        "related": {
          "methods": [
            "method:query.NewQueryBuilder",
            "method:query.QueryBuilder.Where",
            "method:query.QueryBuilder.OrderByAsc",
            "method:query.QueryBuilder.Limit",
            "method:query.QueryBuilder.Select"
          ],
          "errors": [
            "error:failed to read data from collection"
          ]
        }
      },
      "Using Go Functions": {
        "id": "pattern:Using Go Functions",
        "description": "Demonstrates how to extend Anansi's querying capabilities by registering custom Go functions as `ComputeFunction` (for computed fields) and `PredicateFunction` (for custom filters) to handle logic not natively supported by SQL or for post-query processing.",
        "example": {
          "code": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n\t\"github.com/asaidimu/go-anansi/core/query\"\n)\n\n// Assume 'persistenceSvc' is an initialized *persistence.Persistence and 'collection' is a core.PersistenceCollectionInterface\nfunc demonstrateGoFunctions(persistenceSvc *persistence.Persistence, collection core.PersistenceCollectionInterface) {\n\t// 1. Register a Go Compute Function: creates 'full_name' from 'first_name' and 'last_name'\n\tpersistenceSvc.RegisterComputeFunction(\"full_name_fn\", func(row query.Document, args query.FilterValue) (any, error) {\n\t\tfirstName, ok1 := row[\"first_name\"].(string)\n\t\tlastName, ok2 := row[\"last_name\"].(string)\n\t\tif ok1 && ok2 { return fmt.Sprintf(\"%s %s\", firstName, lastName), nil }\n\t\treturn \"\", fmt.Errorf(\"missing name parts\")\n\t})\n\n\t// 2. Register a Go Filter Function: checks if 'age' is 'eligible_for_discount' (e.g., age > 60)\n\tpersistenceSvc.RegisterFilterFunction(\"eligible_for_discount\", func(doc query.Document, field string, args query.FilterValue) (bool, error) {\n\t\tage, ok := doc[\"age\"].(int64)\n\t\tif ok { return age > 60, nil }\n\t\treturn false, nil\n\t})\n\n\t// Insert some sample data\n\tcollection.Create(map[string]any{\"first_name\": \"John\", \"last_name\": \"Doe\", \"age\": 65})\n\tcollection.Create(map[string]any{\"first_name\": \"Jane\", \"last_name\": \"Smith\", \"age\": 30})\n\n\t// Query using the registered computed field\n\tqueryWithComputed := query.NewQueryBuilder().\n\t\tSelect().\n\t\t\tInclude(\"id\", \"first_name\", \"last_name\", \"age\"). // Must include base fields\n\t\t\tAddComputed(\"full_name\", \"full_name_fn\").\n\t\tEnd().\n\t\tBuild()\n\n\tresultComputed, _ := collection.Read(queryWithComputed)\n\tfmt.Println(\"\\n--- Users with Computed Full Name ---\")\n\tfor _, r := range resultComputed.(*query.QueryResult).Data.([]query.Document) {\n\t\tfmt.Printf(\"ID: %v, Name: %v, Age: %v, Full Name: %v\\n\", r[\"id\"], r[\"first_name\"], r[\"age\"], r[\"full_name\"])\n\t}\n\n\t// Query using the registered custom filter\n\tqueryWithFilter := query.NewQueryBuilder().\n\t\tWhere(\"age\").Custom(\"eligible_for_discount\", nil). // Field argument is 'age'\n\t\tBuild()\n\n\tresultFilter, _ := collection.Read(queryWithFilter)\n\tfmt.Println(\"\\n--- Users Eligible for Discount ---\")\n\tfor _, r := range resultFilter.(*query.QueryResult).Data.([]query.Document) {\n\t\tfmt.Printf(\"ID: %v, Name: %v, Age: %v\\n\", r[\"id\"], r[\"first_name\"], r[\"age\"])\n\t}\n}\n",
          "validation": "The queries will execute successfully. The 'full_name' field will be present in the computed query results. Only users matching the 'eligible_for_discount' logic will be returned by the filtered query. No errors related to 'unregistered Go function' should occur."
        },
        "related": {
          "methods": [
            "method:persistence.Executor.RegisterComputeFunction",
            "method:persistence.Executor.RegisterFilterFunction",
            "method:query.ProjectionBuilder.AddComputed",
            "method:query.FilterConditionBuilder.Custom"
          ],
          "errors": [
            "error:unregistered Go filter function",
            "error:unregistered Go compute function",
            "error:error executing Go compute function"
          ]
        }
      },
      "Transaction Management": {
        "id": "pattern:Transaction Management",
        "description": "Executes a block of database operations atomically using `persistence.Persistence.Transact()`. If the callback function returns an error, all changes within the block are rolled back.",
        "example": {
          "code": "package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n\t\"github.com/asaidimu/go-anansi/core/persistence\"\n)\n\n// Assume 'persistenceSvc' is an initialized *persistence.Persistence\nfunc performTransactionalOperations(persistenceSvc *persistence.Persistence) {\n\tresult, err := persistenceSvc.Transact(func(tx core.PersistenceTransactionInterface) (any, error) {\n\t\t// Get a transactional collection instance. All operations on 'usersTxCollection' are part of THIS transaction.\n\t\tusersTxCollection, err := tx.Collection(\"users\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to get transactional users collection: %w\", err)\n\t\t}\n\n\t\t// Perform operations. If any operation here returns an error, the entire transaction will be rolled back.\n\t\t_, err = usersTxCollection.Create(map[string]any{\n\t\t\t\"name\": \"Temporary User\",\n\t\t\t\"email\": \"temp@example.com\",\n\t\t\t\"age\": 25,\n\t\t\t\"is_active\": true,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to create temporary user in transaction: %w\", err)\n\t\t}\n\t\tfmt.Println(\"Temporary user created within transaction.\")\n\n\t\t// Simulate a condition that might cause a rollback (uncomment to test rollback)\n\t\t// return nil, fmt.Errorf(\"simulating an error to trigger rollback\")\n\n\t\treturn \"All transactional operations succeeded!\", nil // Return a value to be passed out of Transact\n\t})\n\n\tif err != nil {\n\t\tfmt.Printf(\"Transaction failed: %v\\n\", err)\n\t} else {\n\t\tfmt.Printf(\"Transaction succeeded with result: %v\\n\", result)\n\t}\n}\n",
          "validation": "If the callback returns `nil` error, the transaction should commit, and changes should persist. If the callback returns an error, the transaction should rollback, and no changes should be visible in the database. The `Transact` method's return value (`result`, `err`) indicates the outcome."
        },
        "related": {
          "methods": [
            "method:persistence.Persistence.Transact",
            "method:sqlite.SQLiteInteractor.StartTransaction",
            "method:sqlite.SQLiteInteractor.Commit",
            "method:sqlite.SQLiteInteractor.Rollback"
          ],
          "errors": [
            "error:Transaction failed"
          ]
        }
      },
      "Event Subscription": {
        "id": "pattern:Event Subscription",
        "description": "Registers a callback function to be executed when specific persistence events occur (e.g., document creation, deletion). Useful for auditing, logging, or triggering reactive logic.",
        "example": {
          "code": "package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"github.com/asaidimu/go-anansi/core\"\n)\n\n// Assume 'collection' is an initialized core.PersistenceCollectionInterface\nfunc setupEventSubscription(collection core.PersistenceCollectionInterface) {\n\t// Define the callback function for DocumentCreateSuccess events\n\tonDocumentCreateSuccess := func(ctx context.Context, event core.PersistenceEvent) error {\n\t\tfmt.Printf(\"\\n[EVENT RECEIVED] Document created in '%s' at %d. Output: %+v\\n\",\n\t\t\t*event.Collection, event.Timestamp, event.Output)\n\t\t// For example, you could send a notification, update a cache, etc.\n\t\treturn nil // Return nil for success, or an error if event processing fails\n\t}\n\n\t// Register the subscription\n\tsubscriptionID := collection.RegisterSubscription(core.RegisterSubscriptionOptions{\n\t\tEvent:       core.DocumentCreateSuccess,\n\t\tCallback:    onDocumentCreateSuccess,\n\t\tLabel:       core.StringPtr(\"my_create_logger\"),\n\t\tDescription: core.StringPtr(\"Logs details of new documents after creation.\"),\n\t})\n\tfmt.Printf(\"Subscription registered with ID: %s\\n\", subscriptionID)\n\n\t// Now, perform an operation that triggers the event\n\t_, err := collection.Create(map[string]any{\n\t\t\"name\": \"EventTriggered User\",\n\t\t\"email\": \"event@example.com\",\n\t\t\"age\": 42,\n\t\t\"is_active\": true,\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to create user to trigger event: %v\", err)\n\t}\n\tfmt.Println(\"User created, check console for event output.\")\n\n\t// To unregister later (optional)\n\t// collection.UnregisterSubscription(subscriptionID)\n}\n",
          "validation": "After running the example, observe the console output. You should see a log message from `[EVENT RECEIVED]` immediately after the `collection.Create()` call, indicating that the `onDocumentCreateSuccess` callback was successfully triggered by the `DocumentCreateSuccess` event."
        },
        "related": {
          "methods": [
            "method:persistence.Collection.RegisterSubscription",
            "method:persistence.Collection.UnregisterSubscription"
          ],
          "errors": []
        }
      }
    },
    "errors": {
      "Failed to open database connection": {
        "id": "error:Failed to open database connection",
        "type": "`*os.PathError` or `*sqlite3.Error`",
        "symptoms": "Application crashes or exits prematurely during database initialization. Error message `Failed to open database connection: ...` is logged.",
        "properties": "The underlying error often contains details about the file path, permissions, or SQLite driver issues.",
        "scenarios": [
          {
            "trigger": "Attempting to open an SQLite database file at an inaccessible path or with insufficient permissions.",
            "example": "```go\n_, err := sql.Open(\"sqlite3\", \"/root/inaccessible/db.db\") // Path with no write permissions\n```",
            "reason": "The operating system prevents the application from creating or opening the specified database file."
          },
          {
            "trigger": "Missing `_ \"github.com/mattn/go-sqlite3\"` import statement or incorrect installation of the SQLite C library.",
            "example": "```go\n// Missing import: _ \"github.com/mattn/go-sqlite3\"\ndb, err := sql.Open(\"sqlite3\", \"user.db\")\n```",
            "reason": "The `database/sql` package cannot find the registered driver for `sqlite3`."
          }
        ],
        "diagnosis": "Check file permissions and path validity. Verify `go.mod` and `go.sum` for `go-sqlite3` and ensure the SQLite C library is correctly installed on the system.",
        "resolution": "Grant necessary file permissions. Install the SQLite C library if missing (e.g., `sudo apt-get install libsqlite3-dev` on Debian/Ubuntu). Ensure the blank import for `go-sqlite3` is present.",
        "prevention": "Always handle `os.IsNotExist` error when attempting to remove old database files. Ensure database paths are user-writable. Verify all prerequisites for `go-sqlite3` installation.",
        "handlingPatterns": "Catch the error during `sql.Open()` and log it, then terminate the application gracefully as a database connection is critical.",
        "propagationBehavior": "Typically propagated directly from `sql.Open()` to the caller. In `main.go`, it's caught and results in a `log.Fatalf`."
      },
      "Failed to unmarshal user schema JSON": {
        "id": "error:Failed to unmarshal user schema JSON",
        "type": "`*json.SyntaxError` or `*json.UnmarshalTypeError`",
        "symptoms": "Application crashes or exits prematurely after loading a JSON schema string. Error message `Failed to unmarshal user schema JSON: ...` is logged.",
        "properties": "The underlying error (`err`) will often detail the exact line and column where the JSON parsing failed, or what type was expected vs. received.",
        "scenarios": [
          {
            "trigger": "The `userSchemaJSON` string contains invalid JSON syntax (e.g., missing comma, unquoted key, extra brace).",
            "example": "```go\nuserSchemaJSON = `{ \"name\": \"users\", \"fields\": { \"id\": { \"type\": \"integer\" } \"name\": { \"type\": \"string\" }}}` // Missing comma\n```",
            "reason": "The `json.Unmarshal` function encounters a syntax error in the provided JSON string."
          },
          {
            "trigger": "The `userSchemaJSON` string contains valid JSON but its structure or data types do not match the `core.SchemaDefinition` Go struct (e.g., `\"fields\"` is an array instead of an object).",
            "example": "```go\nuserSchemaJSON = `{ \"name\": \"users\", \"fields\": []}` // Expected object for fields\n```",
            "reason": "The JSON structure does not map correctly to the target Go struct's fields or expected types."
          }
        ],
        "diagnosis": "Copy the JSON string into a JSON linter or validator tool to check for syntax errors. Compare the JSON structure against the `core.SchemaDefinition` Go struct.",
        "resolution": "Correct the JSON syntax or structure to align with the `core.SchemaDefinition`.",
        "prevention": "Use multiline string literals or embed schema files directly. Employ automated JSON validation tools or build-time checks if schemas are external.",
        "handlingPatterns": "Catch the error during `json.Unmarshal()`. Log the detailed error message to help pinpoint the issue in the schema definition. This error usually warrants application termination if the schema is fundamental.",
        "propagationBehavior": "Propagated directly from `json.Unmarshal()` to the caller. In `main.go`, it's caught and results in a `log.Fatalf`."
      },
      "Failed to create collection": {
        "id": "error:Failed to create collection",
        "type": "`fmt.Errorf` (wrapped `error` from `sqlite.SQLiteInteractor.CreateCollection`)",
        "symptoms": "Application fails to create a database table for a collection. Error message `Failed to create collection 'users': ...` is logged.",
        "properties": "The wrapped error provides specifics, such as `A collection with a similar name exists` or `failed to execute SQL statement`.",
        "scenarios": [
          {
            "trigger": "Attempting to create a collection (`persistenceSvc.Create()`) with a name that already exists in the database.",
            "example": "```go\npersistenceSvc.Create(userSchema) // First call\npersistenceSvc.Create(userSchema) // Second call with same name without prior deletion\n```",
            "reason": "Anansi's internal check (`CollectionExists`) or the underlying database's `CREATE TABLE` command (without `IF NOT EXISTS`) detects an existing table/schema entry."
          },
          {
            "trigger": "The `core.SchemaDefinition` contains invalid field types, constraints, or index definitions that cannot be translated into valid SQL DDL.",
            "example": "```go\n// Imagine a schema with an unsupported FieldType like \"custom_type\"\n// or a malformed index definition.\n```",
            "reason": "The `sqlite.SQLiteInteractor.CreateCollection` or its internal DDL generation (`CreateTableSQL`, `CreateIndexSQL`) encounters an issue translating the schema into valid SQL."
          },
          {
            "trigger": "A database-level constraint violation or other SQL error during table or index creation (e.g., insufficient permissions for DDL).",
            "example": "```go\n// Database user lacks CREATE TABLE privilege\n```",
            "reason": "The underlying `sql.DB.Exec` call for DDL statements fails at the database layer."
          }
        ],
        "diagnosis": "Check if a collection with the same name already exists (`persistenceSvc.Collections()`). Inspect the `core.SchemaDefinition` for validity. Check database permissions and logs for specific SQL errors.",
        "resolution": "Use a unique collection name. Correct invalid schema definitions. Ensure database user has necessary DDL privileges.",
        "prevention": "Always check for collection existence before creating, or use `DropIfExists: true` in `InteractorOptions` during development. Validate schema definitions carefully before deployment.",
        "handlingPatterns": "Catch the error after `persistenceSvc.Create()`. Log details and inform the user about naming conflicts or schema issues.",
        "propagationBehavior": "Propagated from `persistence.Persistence.Create()` to the caller. In `main.go`, it's caught and results in a `log.Fatalf`."
      },
      "Failed to get collection": {
        "id": "error:Failed to get collection",
        "type": "`fmt.Errorf` (wrapped `error` from `persistence.Persistence.Schema`)",
        "symptoms": "Application fails to retrieve a `PersistenceCollectionInterface` instance. Error message `Failed to get collection 'users': ...` is logged.",
        "properties": "The wrapped error indicates whether the collection `does not exist` or if there was an `Error reading schema collection`.",
        "scenarios": [
          {
            "trigger": "Attempting to retrieve a collection instance for a collection name that has not been created yet.",
            "example": "```go\npersistenceSvc.Collection(\"non_existent_collection\")\n```",
            "reason": "The `persistence.Persistence.Collection()` method cannot find the schema record for the specified collection in its internal `_schemas` collection."
          },
          {
            "trigger": "Corruption or unexpected state in the internal `_schemas` collection, preventing the retrieval or unmarshaling of a collection's schema.",
            "example": "```go\n// Direct manual tampering of the _schemas table in user.db\n```",
            "reason": "The schema lookup or unmarshaling process fails due to invalid data in the `_schemas` table."
          }
        ],
        "diagnosis": "Verify that `persistenceSvc.Create()` was successfully called for the collection. Inspect the `_schemas` table in the database (`sqlite3 user.db -> SELECT * FROM _schemas;`) for any inconsistencies.",
        "resolution": "Ensure collection is created before attempting to retrieve it. If `_schemas` is corrupted, consider recreating the database (for dev) or implementing schema repair logic (for prod).",
        "prevention": "Always create collections using Anansi's `persistence.Persistence.Create()` method. Avoid direct manipulation of the `_schemas` table.",
        "handlingPatterns": "Catch the error and provide a user-friendly message, potentially suggesting collection creation if it's a new collection.",
        "propagationBehavior": "Propagated from `persistence.Persistence.Collection()` to the caller. In `main.go`, it's caught and results in a `log.Fatalf`."
      },
      "Provided data does not conform to the collections schema": {
        "id": "error:Provided data does not conform to the collections schema",
        "type": "`fmt.Errorf` (wrapped `fmt.Errorf` from `core.Validator.Validate`)",
        "symptoms": "Document `Create` or `Update` operations fail, indicating schema validation issues. The `collection.Create` or `collection.Update` call returns this specific error.",
        "properties": "This is a high-level error message wrapping the detailed validation issues from `core.Validator`. The wrapped error usually contains specific validation failure codes and messages.",
        "scenarios": [
          {
            "trigger": "Attempting to insert a document with missing `required` fields.",
            "example": "```go\ncollection.Create(map[string]any{\"email\": \"test@example.com\"}) // 'name' is required\n```",
            "reason": "The `core.Validator` detects that a field marked as required in `SchemaDefinition` is absent in the input data."
          },
          {
            "trigger": "Attempting to insert a document with incorrect data types for fields (e.g., a string for an integer field).",
            "example": "```go\ncollection.Create(map[string]any{\"name\": \"Test\", \"email\": \"t@e.com\", \"age\": \"twenty\"})\n```",
            "reason": "The `core.Validator` detects a type mismatch between the input data and the `FieldType` defined in the schema."
          },
          {
            "trigger": "Attempting to insert a document that violates a `unique` constraint or `enum` value list, or fails a custom `Constraint`.",
            "example": "```go\ncollection.Create(map[string]any{\"name\": \"A\", \"email\": \"a@b.com\"}) // First time\ncollection.Create(map[string]any{\"name\": \"B\", \"email\": \"a@b.com\"}) // Second time, 'email' is unique\n```",
            "reason": "The `core.Validator` (or the underlying database for unique constraints) detects a violation of a schema-defined constraint."
          }
        ],
        "diagnosis": "Call `collection.Validate(data, false)` on the input data to get a `*core.ValidationResult`. Examine the `ValidationResult.Issues` slice for specific error codes, messages, and paths.",
        "resolution": "Correct the input data to conform to the schema's requirements (add missing fields, fix types, adhere to constraints).",
        "prevention": "Implement client-side validation using the schema before calling persistence operations. Always refer to the `core.SchemaDefinition` for data shape requirements.",
        "handlingPatterns": "Catch this error and use `collection.Validate()` to provide detailed feedback to the user or for internal debugging.",
        "propagationBehavior": "Originates from `persistence.Collection.Create()` or `persistence.Collection.Update()` after validation fails."
      },
      "failed to insert data": {
        "id": "error:failed to insert data",
        "type": "`fmt.Errorf` (wrapped `error` from `persistence.Executor.Insert`)",
        "symptoms": "Document creation fails at the database insertion step, even after passing schema validation.",
        "properties": "The wrapped error often contains specific SQL errors from the database driver, such as primary key conflicts, unique constraint violations (if not caught by `core.Validator`), or data integrity issues.",
        "scenarios": [
          {
            "trigger": "A database-level unique constraint violation (e.g., trying to insert a duplicate email if `email` is unique) not caught by `core.Validator` (e.g., if `unique` field not properly mapped in `FieldDefinition`).",
            "example": "```go\ncollection.Create(user1) // email: \"test@example.com\"\ncollection.Create(user2) // email: \"test@example.com\"\n```",
            "reason": "The database rejects the `INSERT` operation due to a violation of a unique index or primary key constraint."
          },
          {
            "trigger": "Data integrity issues not fully captured by schema (e.g., a foreign key constraint violation if Anansi supported FKs).",
            "example": "N/A with current code, but conceptually.",
            "reason": "The database rejects the insert due to a rule it enforces."
          },
          {
            "trigger": "SQLite version older than 3.35.0 when `RETURNING *` is used in generated SQL.",
            "example": "```go\n// Code with `collection.Create()` on SQLite < 3.35.0\n```",
            "reason": "The database SQL dialect is not supported."
          }
        ],
        "diagnosis": "Inspect the detailed error message (especially the wrapped one) for the underlying SQL error code or message. Check database logs. Confirm SQLite version if `RETURNING *` is suspected.",
        "resolution": "Correct the data to avoid database constraints. Upgrade SQLite if necessary.",
        "prevention": "Ensure `core.SchemaDefinition` accurately reflects all database constraints, allowing `core.Validator` to catch issues pre-database.",
        "handlingPatterns": "Catch the error during `collection.Create()`. Log it and inform the user about potential data conflicts.",
        "propagationBehavior": "Propagated from `persistence.Collection.Create()` to the caller."
      },
      "Input to read is not a valid QueryDSL": {
        "id": "error:Input to read is not a valid QueryDSL",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Read()` results in an error indicating an invalid input type.",
        "properties": "The error message explicitly states that `Input to read is not a valid QueryDSL`.",
        "scenarios": [
          {
            "trigger": "Passing a value other than `query.QueryDSL` to `collection.Read()`.",
            "example": "```go\ncollection.Read(map[string]any{\"name\": \"Alice\"}) // Passing a map instead of QueryDSL\n```",
            "reason": "The `collection.Read()` method expects a `query.QueryDSL` struct (or `query.QueryDSL` returned by `query.NewQueryBuilder().Build()`) as its `input` parameter."
          }
        ],
        "diagnosis": "Verify that the argument passed to `collection.Read()` is the result of `query.NewQueryBuilder()...Build()`.",
        "resolution": "Always construct your queries using `query.NewQueryBuilder()` and call its `Build()` method.",
        "prevention": "Enforce type checking by using the correct type signature for `query.QueryDSL` in function parameters.",
        "handlingPatterns": "Log the error and inform the developer about the expected input type for `collection.Read()`.",
        "propagationBehavior": "Originates from `persistence.Collection.Read()`."
      },
      "invalid params type for Update": {
        "id": "error:invalid params type for Update",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Update()` results in an error indicating an invalid `params` type.",
        "properties": "The error message explicitly states `invalid params type for Update: expected query.QueryFilter, got %T`.",
        "scenarios": [
          {
            "trigger": "The `Filter` field within `core.CollectionUpdate` is not a `*query.QueryFilter` (e.g., it's `nil`, a plain map, or a raw `QueryDSL`).",
            "example": "```go\ncollection.Update(&core.CollectionUpdate{\n    Data: map[string]any{\"age\": 31},\n    Filter: query.NewQueryBuilder().Where(\"email\").Eq(\"alice@example.com\").Build(), // Passed QueryDSL instead of QueryFilter\n})\n```",
            "reason": "The `collection.Update()` method expects the `Filter` field of `core.CollectionUpdate` to be specifically `*query.QueryFilter`, which is accessible via `QueryDSL.Filters`."
          }
        ],
        "diagnosis": "Ensure that when building `core.CollectionUpdate`, the `Filter` field is assigned the `.Filters` property of a built `QueryDSL` (e.g., `query.NewQueryBuilder()...Build().Filters`).",
        "resolution": "Correct the type of the `Filter` field to `*query.QueryFilter`.",
        "prevention": "Always use `QueryDSL.Filters` when passing filters to `collection.Update()`.",
        "handlingPatterns": "Log the error and guide the developer to correctly extract the filter from `QueryDSL`.",
        "propagationBehavior": "Originates from `persistence.Collection.Update()`."
      },
      "failed to read data from collection": {
        "id": "error:failed to read data from collection",
        "type": "`fmt.Errorf` (wrapped `error` from `persistence.Executor.Query`)",
        "symptoms": "A `Read` or `Update` operation fails at the underlying database read step.",
        "properties": "This is a general error wrapping more specific issues from the `Executor.Query()` method, such as SQL execution errors.",
        "scenarios": [
          {
            "trigger": "The generated SQL query contains an error that the database cannot execute (e.g., invalid column name, syntax error).",
            "example": "```go\n// Imagine a QueryDSL with a non-existent field name.\n```",
            "reason": "The `sqlite.SqliteQuery.GenerateSelectSQL` produces invalid SQL, or the underlying database connection encounters an error during `QueryContext`."
          },
          {
            "trigger": "Network issues or database server unavailability.",
            "example": "```go\n// Database connection dropped unexpectedly.\n```",
            "reason": "The database driver fails to communicate with the database."
          }
        ],
        "diagnosis": "Examine the full error message for the underlying SQL error. Check database connectivity. If using `zap.NewDevelopment()`, look for the `Executing SQL SELECT` logs to review the generated SQL and parameters.",
        "resolution": "Correct the `QueryDSL` definition if it's causing invalid SQL. Troubleshoot database connectivity.",
        "prevention": "Thoroughly test complex queries. Implement retry mechanisms for transient database errors.",
        "handlingPatterns": "Catch this error, log the full error stack, and inform the user of a data retrieval failure.",
        "propagationBehavior": "Propagates from `persistence.Collection.Read()` or `persistence.Collection.Update()`."
      },
      "invalid params type for Delete": {
        "id": "error:invalid params type for Delete",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Delete()` results in an error indicating an invalid `params` type.",
        "properties": "The error message explicitly states `invalid params type for Delete: expected query.QueryFilter, got %T`.",
        "scenarios": [
          {
            "trigger": "Passing a value other than `*query.QueryFilter` to `collection.Delete()` as its first argument when `unsafe` is `false`.",
            "example": "```go\ncollection.Delete(map[string]any{\"age\": 25}, false) // Passing a map instead of *query.QueryFilter\n```",
            "reason": "The `collection.Delete()` method expects its `params` argument to be `*query.QueryFilter` unless `unsafe` is true."
          }
        ],
        "diagnosis": "Ensure that the first argument to `collection.Delete()` is `*query.QueryFilter` (e.g., `query.NewQueryBuilder()...Build().Filters`) or `nil` if `unsafe` is `true`.",
        "resolution": "Correct the type of the `params` argument to `*query.QueryFilter`.",
        "prevention": "Always use `QueryDSL.Filters` when providing filters to `collection.Delete()` unless a full-table delete is intended.",
        "handlingPatterns": "Log the error and guide the developer to correctly provide the filter.",
        "propagationBehavior": "Originates from `persistence.Collection.Delete()`."
      },
      "failed to delete data": {
        "id": "error:failed to delete data",
        "type": "`fmt.Errorf` (wrapped `error` from `persistence.Executor.Delete`)",
        "symptoms": "A `Delete` operation fails at the underlying database deletion step.",
        "properties": "This is a general error wrapping more specific issues from the `Executor.Delete()` method, such as SQL execution errors.",
        "scenarios": [
          {
            "trigger": "The generated SQL `DELETE` query contains an error (e.g., invalid column name, syntax error).",
            "example": "```go\n// Imagine a QueryFilter with a non-existent field name.\n```",
            "reason": "The `sqlite.SqliteQuery.GenerateDeleteSQL` produces invalid SQL, or the underlying database connection encounters an error during `ExecContext`."
          },
          {
            "trigger": "Database-level constraints preventing deletion (e.g., foreign key constraints if supported and enabled).",
            "example": "N/A with current code, but conceptually.",
            "reason": "The database rejects the delete due to an integrity rule."
          }
        ],
        "diagnosis": "Examine the full error message for the underlying SQL error. Check database logs. If using `zap.NewDevelopment()`, review the generated SQL and parameters.",
        "resolution": "Correct the `QueryFilter` definition if it's causing invalid SQL. Address database-level constraints if applicable.",
        "prevention": "Thoroughly test deletion queries. Ensure schema constraints don't unintentionally block necessary deletions.",
        "handlingPatterns": "Catch this error, log the full error stack, and inform the user of a data deletion failure.",
        "propagationBehavior": "Propagates from `persistence.Collection.Delete()`."
      },
      "Failed to convert data to a map": {
        "id": "error:Failed to convert data to a map",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Validate()` results in an error indicating the input data cannot be converted to `map[string]any`.",
        "properties": "The error message explicitly states `Failed to convert data to a map`.",
        "scenarios": [
          {
            "trigger": "Passing a value to `collection.Validate()` that is not of type `map[string]any`.",
            "example": "```go\ncollection.Validate([]string{\"a\", \"b\"}, false) // Passing a slice instead of a map\n```",
            "reason": "The `persistence.CollectionBase.Validate()` method (delegated to by `persistence.Collection`) performs a type assertion to `map[string]any` and it fails."
          }
        ],
        "diagnosis": "Ensure the `data` argument passed to `collection.Validate()` is a `map[string]any`.",
        "resolution": "Provide input data as a `map[string]any`.",
        "prevention": "Design functions to accept or validate expected input types early.",
        "handlingPatterns": "Log the error and instruct the developer on the correct input type.",
        "propagationBehavior": "Originates from `persistence.Collection.Validate()`."
      },
      "Rollback method stub": {
        "id": "error:Rollback method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Rollback()` or `persistence.Persistence.Rollback()` (global) results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `Rollback method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `Rollback` method on either `core.PersistenceCollectionInterface` or `core.PersistenceInterface`.",
            "example": "```go\ncollection.Rollback(nil, nil)\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "Migrate method stub": {
        "id": "error:Migrate method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Migrate()` results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `Migrate method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `Migrate` method on `core.PersistenceCollectionInterface`.",
            "example": "```go\ncollection.Migrate(\"Initial migration\", nil, nil)\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "Collection metadata method stub": {
        "id": "error:Collection metadata method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.Metadata()` results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `Collection metadata method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `Metadata` method on `core.PersistenceCollectionInterface`.",
            "example": "```go\ncollection.Metadata(nil, false)\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "RegisterTrigger method stub": {
        "id": "error:RegisterTrigger method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.RegisterTrigger()` or `persistence.Persistence.RegisterTrigger()` results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `RegisterTrigger method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `RegisterTrigger` method on either `core.PersistenceCollectionInterface` or `core.PersistenceInterface`.",
            "example": "```go\ncollection.RegisterTrigger(core.RegisterTriggerOptions{ /* ... */ })\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "UnregisterTrigger method stub": {
        "id": "error:UnregisterTrigger method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.UnregisterTrigger()` or `persistence.Persistence.UnregisterTrigger()` results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `UnregisterTrigger method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `UnregisterTrigger` method on either `core.PersistenceCollectionInterface` or `core.PersistenceInterface`.",
            "example": "```go\ncollection.UnregisterTrigger(core.UnregisterTriggerOptions{CallbackID: \"someid\"})\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "RegisterTask method stub": {
        "id": "error:RegisterTask method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.RegisterTask()` or `persistence.Persistence.RegisterTask()` results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `RegisterTask method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `RegisterTask` method on either `core.PersistenceCollectionInterface` or `core.PersistenceInterface`.",
            "example": "```go\ncollection.RegisterTask(core.RegisterTaskOptions{ /* ... */ })\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "UnregisterTask method stub": {
        "id": "error:UnregisterTask method stub",
        "type": "`fmt.Errorf`",
        "symptoms": "Calling `collection.UnregisterTask()` or `persistence.Persistence.UnregisterTask()` results in an error indicating the method is a stub.",
        "properties": "The error message explicitly states `UnregisterTask method stub`.",
        "scenarios": [
          {
            "trigger": "Invoking the `UnregisterTask` method on either `core.PersistenceCollectionInterface` or `core.PersistenceInterface`.",
            "example": "```go\ncollection.UnregisterTask(core.UnregisterTaskOptions{CallbackID: \"someid\"})\n```",
            "reason": "This method's implementation is currently a placeholder in the Anansi framework roadmap."
          }
        ],
        "diagnosis": "Recognize that this feature is not yet fully implemented.",
        "resolution": "Avoid using this method or contribute to its implementation.",
        "prevention": "Refer to the Anansi roadmap; use only implemented features.",
        "handlingPatterns": "Not applicable for users, but for developers, indicates a feature in progress.",
        "propagationBehavior": "Directly returned by the stubbed method."
      },
      "unregistered Go filter function": {
        "id": "error:unregistered Go filter function",
        "type": "`fmt.Errorf`",
        "symptoms": "A `Read` query containing a `Custom` filter operation fails with this error. The error message will specify the operator that is unregistered.",
        "properties": "The error message will contain the `